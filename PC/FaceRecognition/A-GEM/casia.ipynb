{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cal-05/anaconda3/envs/hspark/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pickle\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.util import get_image_list, dataset_list, PathDataset, PathDataset_v2, make_task\n",
    "\n",
    "from avalanche.training.supervised import AGEM\n",
    "from avalanche.logging import InteractiveLogger, TensorboardLogger\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "cudnn.enabled = False\n",
    "cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    # transforms.Resize(224),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  66487\n",
      "test :  16622\n"
     ]
    }
   ],
   "source": [
    "incremental = 1000\n",
    "data_path = \"../Data/CASIA-WebFace/\" \n",
    "\n",
    "dataset = get_image_list(data_path)\n",
    "\n",
    "image_dataset = []\n",
    "label_dataset = []\n",
    "incremental_list = list(range(incremental))\n",
    "\n",
    "for idx, label in enumerate(dataset[1]):\n",
    "    if label in incremental_list:\n",
    "        image_dataset.append(dataset[0][idx])\n",
    "        label_dataset.append(dataset[1][idx])\n",
    "\n",
    "# x_train, x_test, y_train, y_test = train_test_split(dataset[0], dataset[1], test_size=0.2, shuffle=True, random_state=seed, stratify=dataset[1])\n",
    "x_train, x_test, y_train, y_test = train_test_split(image_dataset, label_dataset, test_size=0.2, shuffle=True, random_state=seed, stratify=label_dataset)\n",
    "\n",
    "train_set = dataset_list(x_train, y_train)\n",
    "test_set = dataset_list(x_test, y_test)\n",
    "\n",
    "print(\"train : \", len(y_train))\n",
    "print(\"test : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_group = dict(\n",
    "       train=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       ),\n",
    "       eval=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:2' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# num_class = 10575\n",
    "# train_task = make_task(incremental, y_train)\n",
    "# test_task = make_task(incremental, y_test)\n",
    "\n",
    "# train_set = PathDataset(train_set, transforms_group, \"train\", train_task)\n",
    "# test_set = PathDataset(test_set, transforms_group, \"eval\", test_task)\n",
    "train_set = PathDataset_v2(train_set, transforms_group, \"train\")\n",
    "test_set = PathDataset_v2(test_set, transforms_group, \"eval\")\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=False,\n",
    "                        seed=seed,\n",
    "                        shuffle=True\n",
    "                        )\n",
    "\n",
    "model = torchvision.models.resnet18(pretrained=False, num_classes=incremental)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-09 17:10:06.300002: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "/home/cal-05/anaconda3/envs/hspark/lib/python3.8/site-packages/avalanche/training/plugins/evaluation.py:81: UserWarning: No benchmark provided to the evaluation plugin. Metrics may be computed on inconsistent portion of streams, use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "tensor_logger = TensorboardLogger(\"logs_agme_casia\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, tensor_logger])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A-GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 10\n",
    "eval_batch = 10\n",
    "epoch = 1\n",
    "memory_size = 50\n",
    "\n",
    "strategies = AGEM(model, optimizer, criterion, patterns_per_exp=memory_size, sample_size=memory_size, train_epochs=epoch, device=device, train_mb_size=train_batch, eval_mb_size=eval_batch, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Starting experiment...\")\n",
    "results = []\n",
    "\n",
    "for experience in scenario.train_stream:\n",
    "    print(\"Start training on experience \", experience.current_experience)\n",
    "\n",
    "    strategies.train(experience)\n",
    "    print(\"End training on experience \", experience.current_experience)\n",
    "    print(\"Computing accuracy on the test set\")\n",
    "    results.append(strategies.eval(scenario.test_stream[:]))\n",
    "\n",
    "# save result\n",
    "log_path = \"./logs.txt\"\n",
    "with open(log_path, 'wb') as lf:\n",
    "    pickle.dump(results, lf)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7200c97f9580f269913cae0521a31c8c9bc2a022b66e7eee6f7caa3cb908faad"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('hspark')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
