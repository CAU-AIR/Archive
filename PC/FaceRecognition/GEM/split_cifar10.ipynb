{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.FB5AE2TYXYH2IJRDKGDGQ3XBKLKTF43H.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.util import get_image_list, ImageDataset\n",
    "from avalanche.benchmarks.datasets import CelebA\n",
    "\n",
    "from avalanche.benchmarks.utils import AvalancheTensorDataset\n",
    "from avalanche.training.supervised import GEM\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.benchmarks.utils import AvalancheDataset, AvalancheDatasetType\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.plugins.lr_scheduling import LRSchedulerPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False\n",
    "# torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToPILImage(),\n",
    "    transforms.ToTensor()\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train :  395531\n",
      "test :  98883\n",
      "avalanche dataset x :  <class 'torch.Tensor'>\n",
      "avalanche dataset y :  <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../Data/CASIA-WebFace/\"\n",
    "\n",
    "dataset = get_image_list(data_path)\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset[0], dataset[1], test_size=0.2, shuffle=True, random_state=seed, stratify=dataset[1])\n",
    "\n",
    "train_set = ImageDataset(x_train, y_train)\n",
    "test_set = ImageDataset(x_test, y_test)\n",
    "# train_dataset = TensorDataset(x_train, y_train)\n",
    "# test_dataset = TensorDataset(x_test, y_test)\n",
    "# train_dataset = AvalancheTensorDataset(x_train, y_train)\n",
    "# test_dataset = AvalancheTensorDataset(x_test, y_test)\n",
    "\n",
    "print(\"train : \", len(y_train))\n",
    "print(\"test : \", len(y_test))\n",
    "\n",
    "# # check avalanche dataset\n",
    "x,y = train_set[0]\n",
    "print(\"avalanche dataset x : \", type(x))\n",
    "print(\"avalanche dataset y : \", type(y))\n",
    "\n",
    "## Data imbalance\n",
    "# from collections import Counter\n",
    "# cnt = Counter(dataset[1])\n",
    "# print(\"Target : \", cnt.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transforms_group = dict(\n",
    "       train=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       ),\n",
    "       eval=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       )\n",
    ")\n",
    "\n",
    "train_set = AvalancheDataset(train_dataset, transform_groups=transforms_group, initial_transform_group=\"train\")\n",
    "test_set = AvalancheDataset(test_dataset, transform_groups=transforms_group, initial_transform_group=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhopo55\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.12.21 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.12.17"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>c:\\Users\\LAB\\Desktop\\Archive\\PC\\FaceRecognition\\GEM\\wandb\\run-20220721_175334-25g7u0ja</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href=\"https://wandb.ai/hopo55/Face%20Recognition/runs/25g7u0ja\" target=\"_blank\">GEM-CASIA</a></strong> to <a href=\"https://wandb.ai/hopo55/Face%20Recognition\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\plugins\\evaluation.py:81: UserWarning: No benchmark provided to the evaluation plugin. Metrics may be computed on inconsistent portion of streams, use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(project_name=\"Face Recognition\", run_name=\"GEM-CASIA\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ImageDataset' object has no attribute 'targets'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LAB\\Desktop\\Archive\\PC\\FaceRecognition\\GEM\\split_cifar10.ipynb 셀 7\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=2'>3</a>\u001b[0m num_class \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=3'>4</a>\u001b[0m incremental \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=5'>6</a>\u001b[0m scenario \u001b[39m=\u001b[39m nc_benchmark(train_dataset\u001b[39m=\u001b[39;49mtrain_set,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=6'>7</a>\u001b[0m                         test_dataset\u001b[39m=\u001b[39;49mtest_set,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=7'>8</a>\u001b[0m                         n_experiences\u001b[39m=\u001b[39;49mincremental,\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=8'>9</a>\u001b[0m                         task_labels\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=9'>10</a>\u001b[0m                         seed\u001b[39m=\u001b[39;49mseed,\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=10'>11</a>\u001b[0m                         shuffle\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=11'>12</a>\u001b[0m                         )\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=13'>14</a>\u001b[0m \u001b[39m# model = torchvision.models.resnet18(pretrained=False, num_classes=num_class)\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000005?line=14'>15</a>\u001b[0m model \u001b[39m=\u001b[39m torchvision\u001b[39m.\u001b[39mmodels\u001b[39m.\u001b[39mresnet18(pretrained\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\generators\\benchmark_generators.py:223\u001b[0m, in \u001b[0;36mnc_benchmark\u001b[1;34m(train_dataset, test_dataset, n_experiences, task_labels, shuffle, seed, fixed_class_order, per_exp_classes, class_ids_from_zero_from_first_exp, class_ids_from_zero_in_each_exp, one_dataset_per_exp, train_transform, eval_transform, reproducibility_data)\u001b[0m\n\u001b[0;32m    218\u001b[0m transform_groups \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(\n\u001b[0;32m    219\u001b[0m     train\u001b[39m=\u001b[39m(train_transform, \u001b[39mNone\u001b[39;00m), \u001b[39meval\u001b[39m\u001b[39m=\u001b[39m(eval_transform, \u001b[39mNone\u001b[39;00m)\n\u001b[0;32m    220\u001b[0m )\n\u001b[0;32m    222\u001b[0m \u001b[39m# Datasets should be instances of AvalancheDataset\u001b[39;00m\n\u001b[1;32m--> 223\u001b[0m train_dataset \u001b[39m=\u001b[39m AvalancheDataset(\n\u001b[0;32m    224\u001b[0m     train_dataset,\n\u001b[0;32m    225\u001b[0m     transform_groups\u001b[39m=\u001b[39;49mtransform_groups,\n\u001b[0;32m    226\u001b[0m     initial_transform_group\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mtrain\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    227\u001b[0m     dataset_type\u001b[39m=\u001b[39;49mAvalancheDatasetType\u001b[39m.\u001b[39;49mCLASSIFICATION,\n\u001b[0;32m    228\u001b[0m )\n\u001b[0;32m    230\u001b[0m test_dataset \u001b[39m=\u001b[39m AvalancheDataset(\n\u001b[0;32m    231\u001b[0m     test_dataset,\n\u001b[0;32m    232\u001b[0m     transform_groups\u001b[39m=\u001b[39mtransform_groups,\n\u001b[0;32m    233\u001b[0m     initial_transform_group\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39meval\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    234\u001b[0m     dataset_type\u001b[39m=\u001b[39mAvalancheDatasetType\u001b[39m.\u001b[39mCLASSIFICATION,\n\u001b[0;32m    235\u001b[0m )\n\u001b[0;32m    237\u001b[0m \u001b[39mreturn\u001b[39;00m NCScenario(\n\u001b[0;32m    238\u001b[0m     train_dataset,\n\u001b[0;32m    239\u001b[0m     test_dataset,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    248\u001b[0m     reproducibility_data,\n\u001b[0;32m    249\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:262\u001b[0m, in \u001b[0;36mAvalancheDataset.__init__\u001b[1;34m(self, dataset, transform, target_transform, transform_groups, initial_transform_group, task_labels, targets, dataset_type, collate_fn, targets_adapter)\u001b[0m\n\u001b[0;32m    257\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset_type \u001b[39m=\u001b[39m dataset_type\n\u001b[0;32m    258\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    259\u001b[0m \u001b[39mThe type of this dataset (UNDEFINED, CLASSIFICATION, ...).\u001b[39;00m\n\u001b[0;32m    260\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m--> 262\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets: Sequence[TTargetType] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_initialize_targets_sequence(\n\u001b[0;32m    263\u001b[0m     dataset, targets, dataset_type, targets_adapter\n\u001b[0;32m    264\u001b[0m )\n\u001b[0;32m    265\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    266\u001b[0m \u001b[39mA sequence of values describing the label of each pattern contained in\u001b[39;00m\n\u001b[0;32m    267\u001b[0m \u001b[39mthe dataset.\u001b[39;00m\n\u001b[0;32m    268\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    270\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets_task_labels: Sequence[\n\u001b[0;32m    271\u001b[0m     \u001b[39mint\u001b[39m\n\u001b[0;32m    272\u001b[0m ] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_initialize_task_labels_sequence(dataset, task_labels)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:935\u001b[0m, in \u001b[0;36mAvalancheDataset._initialize_targets_sequence\u001b[1;34m(self, dataset, targets, dataset_type, targets_adapter)\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    934\u001b[0m         targets_adapter \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m--> 935\u001b[0m \u001b[39mreturn\u001b[39;00m _make_target_from_supported_dataset(dataset, targets_adapter)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:2475\u001b[0m, in \u001b[0;36m_make_target_from_supported_dataset\u001b[1;34m(dataset, converter)\u001b[0m\n\u001b[0;32m   2472\u001b[0m \u001b[39mif\u001b[39;00m converter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m   2473\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mtargets\n\u001b[0;32m   2474\u001b[0m \u001b[39melif\u001b[39;00m (\n\u001b[1;32m-> 2475\u001b[0m     \u001b[39misinstance\u001b[39m(dataset\u001b[39m.\u001b[39;49mtargets, (SubSequence, LazyConcatTargets))\n\u001b[0;32m   2476\u001b[0m     \u001b[39mand\u001b[39;00m dataset\u001b[39m.\u001b[39mtargets\u001b[39m.\u001b[39mconverter \u001b[39m==\u001b[39m converter\n\u001b[0;32m   2477\u001b[0m ):\n\u001b[0;32m   2478\u001b[0m     \u001b[39mreturn\u001b[39;00m dataset\u001b[39m.\u001b[39mtargets\n\u001b[0;32m   2479\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(dataset\u001b[39m.\u001b[39mtargets, LazyClassMapping) \u001b[39mand\u001b[39;00m converter \u001b[39m==\u001b[39m \u001b[39mint\u001b[39m:\n\u001b[0;32m   2480\u001b[0m     \u001b[39m# LazyClassMapping already outputs int targets\u001b[39;00m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'ImageDataset' object has no attribute 'targets'"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_class = 10\n",
    "incremental = 5\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=True,\n",
    "                        seed=seed,\n",
    "                        shuffle=False\n",
    "                        )\n",
    "\n",
    "# model = torchvision.models.resnet18(pretrained=False, num_classes=num_class)\n",
    "model = torchvision.models.resnet18(pretrained=False)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-1)\n",
    "criterion = torch.nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GEM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_batch = 256\n",
    "eval_batch = 128\n",
    "epoch = 70\n",
    "\n",
    "strategies = GEM(model, optimizer, criterion, patterns_per_exp=256, memory_strength=0.5, train_epochs=epoch, device=device, train_mb_size=10, evaluator=eval_plugin)  # criterion = ICaRLLossPlugin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "pic should be Tensor or ndarray. Got <class 'str'>.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LAB\\Desktop\\Archive\\PC\\FaceRecognition\\GEM\\split_cifar10.ipynb 셀 10\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000008?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, exp \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(scenario\u001b[39m.\u001b[39mtrain_stream):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000008?line=1'>2</a>\u001b[0m     eval_exps \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m scenario\u001b[39m.\u001b[39mtest_stream][: i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000008?line=2'>3</a>\u001b[0m     strategies\u001b[39m.\u001b[39;49mtrain(exp)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/FaceRecognition/GEM/split_cifar10.ipynb#ch0000008?line=3'>4</a>\u001b[0m     strategies\u001b[39m.\u001b[39meval(eval_exps)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:130\u001b[0m, in \u001b[0;36mBaseSGDTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(\u001b[39mself\u001b[39m,\n\u001b[0;32m    125\u001b[0m           experiences: Union[CLExperience,\n\u001b[0;32m    126\u001b[0m                              ExpSequence],\n\u001b[0;32m    127\u001b[0m           eval_streams: Optional[Sequence[Union[CLExperience,\n\u001b[0;32m    128\u001b[0m                                                 ExpSequence]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    129\u001b[0m           \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m--> 130\u001b[0m     \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mtrain(experiences, eval_streams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    131\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator\u001b[39m.\u001b[39mget_last_metrics()\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\templates\\base.py:107\u001b[0m, in \u001b[0;36mBaseTemplate.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    105\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperience \u001b[39min\u001b[39;00m experiences:\n\u001b[0;32m    106\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_before_training_exp(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m--> 107\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_train_exp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperience, eval_streams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    108\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training_exp(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    109\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:178\u001b[0m, in \u001b[0;36mBaseSGDTemplate._train_exp\u001b[1;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    175\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    176\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> 178\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_epoch(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    179\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training_epoch(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\templates\\base_sgd.py:224\u001b[0m, in \u001b[0;36mBaseSGDTemplate.training_epoch\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_epoch\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    219\u001b[0m     \u001b[39m\"\"\"Training epoch.\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \n\u001b[0;32m    221\u001b[0m \u001b[39m    :param kwargs:\u001b[39;00m\n\u001b[0;32m    222\u001b[0m \u001b[39m    :return:\u001b[39;00m\n\u001b[0;32m    223\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 224\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmbatch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader:\n\u001b[0;32m    225\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_training:\n\u001b[0;32m    226\u001b[0m             \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\data_loader.py:122\u001b[0m, in \u001b[0;36mTaskBalancedDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m--> 122\u001b[0m     \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dl\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m():\n\u001b[0;32m    123\u001b[0m         \u001b[39myield\u001b[39;00m el\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\data_loader.py:194\u001b[0m, in \u001b[0;36mGroupBalancedDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[39mfor\u001b[39;00m tid, t_loader \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(iter_dataloaders):\n\u001b[0;32m    193\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 194\u001b[0m         batch \u001b[39m=\u001b[39m \u001b[39mnext\u001b[39;49m(t_loader)\n\u001b[0;32m    195\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m:\n\u001b[0;32m    196\u001b[0m         \u001b[39m# StopIteration is thrown if dataset ends.\u001b[39;00m\n\u001b[0;32m    197\u001b[0m         \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moversample_small_groups:\n\u001b[0;32m    198\u001b[0m             \u001b[39m# reinitialize data loader\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:530\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    528\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    529\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()\n\u001b[1;32m--> 530\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    531\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    532\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    533\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    534\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:570\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    568\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    569\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 570\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    571\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    572\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:49\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfetch\u001b[39m(\u001b[39mself\u001b[39m, possibly_batched_index):\n\u001b[0;32m     48\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mauto_collation:\n\u001b[1;32m---> 49\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     50\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     51\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:379\u001b[0m, in \u001b[0;36mAvalancheDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[T_co, Sequence[T_co]]:\n\u001b[0;32m    378\u001b[0m     \u001b[39mreturn\u001b[39;00m TupleTLabel(\n\u001b[1;32m--> 379\u001b[0m         manage_advanced_indexing(\n\u001b[0;32m    380\u001b[0m             idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_item, \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn\n\u001b[0;32m    381\u001b[0m         )\n\u001b[0;32m    382\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\dataset_utils.py:382\u001b[0m, in \u001b[0;36mmanage_advanced_indexing\u001b[1;34m(idx, single_element_getter, max_length, collate_fn)\u001b[0m\n\u001b[0;32m    380\u001b[0m elements \u001b[39m=\u001b[39m []\n\u001b[0;32m    381\u001b[0m \u001b[39mfor\u001b[39;00m single_idx \u001b[39min\u001b[39;00m indexes_iterator:\n\u001b[1;32m--> 382\u001b[0m     single_element \u001b[39m=\u001b[39m single_element_getter(\u001b[39mint\u001b[39;49m(single_idx))\n\u001b[0;32m    383\u001b[0m     elements\u001b[39m.\u001b[39mappend(single_element)\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(elements) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:782\u001b[0m, in \u001b[0;36mAvalancheDataset._get_single_item\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_single_item\u001b[39m(\u001b[39mself\u001b[39m, idx: \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 782\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_pattern(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset[idx], idx)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\dataset_utils.py:264\u001b[0m, in \u001b[0;36mClassificationSubset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m--> 264\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49m\u001b[39m__getitem__\u001b[39;49m(idx)\n\u001b[0;32m    266\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_mapping \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    267\u001b[0m         \u001b[39mreturn\u001b[39;00m make_tuple(\n\u001b[0;32m    268\u001b[0m             (result[\u001b[39m0\u001b[39m], \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclass_mapping[result[\u001b[39m1\u001b[39m]], \u001b[39m*\u001b[39mresult[\u001b[39m2\u001b[39m:]), result\n\u001b[0;32m    269\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\dataset_utils.py:237\u001b[0m, in \u001b[0;36mSubsetWithTargets.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    236\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m--> 237\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mindices[idx]]\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:379\u001b[0m, in \u001b[0;36mAvalancheDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[T_co, Sequence[T_co]]:\n\u001b[0;32m    378\u001b[0m     \u001b[39mreturn\u001b[39;00m TupleTLabel(\n\u001b[1;32m--> 379\u001b[0m         manage_advanced_indexing(\n\u001b[0;32m    380\u001b[0m             idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_item, \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn\n\u001b[0;32m    381\u001b[0m         )\n\u001b[0;32m    382\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\dataset_utils.py:382\u001b[0m, in \u001b[0;36mmanage_advanced_indexing\u001b[1;34m(idx, single_element_getter, max_length, collate_fn)\u001b[0m\n\u001b[0;32m    380\u001b[0m elements \u001b[39m=\u001b[39m []\n\u001b[0;32m    381\u001b[0m \u001b[39mfor\u001b[39;00m single_idx \u001b[39min\u001b[39;00m indexes_iterator:\n\u001b[1;32m--> 382\u001b[0m     single_element \u001b[39m=\u001b[39m single_element_getter(\u001b[39mint\u001b[39;49m(single_idx))\n\u001b[0;32m    383\u001b[0m     elements\u001b[39m.\u001b[39mappend(single_element)\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(elements) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:782\u001b[0m, in \u001b[0;36mAvalancheDataset._get_single_item\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_single_item\u001b[39m(\u001b[39mself\u001b[39m, idx: \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 782\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_process_pattern(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset[idx], idx)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:379\u001b[0m, in \u001b[0;36mAvalancheDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Union[T_co, Sequence[T_co]]:\n\u001b[0;32m    378\u001b[0m     \u001b[39mreturn\u001b[39;00m TupleTLabel(\n\u001b[1;32m--> 379\u001b[0m         manage_advanced_indexing(\n\u001b[0;32m    380\u001b[0m             idx, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_single_item, \u001b[39mlen\u001b[39;49m(\u001b[39mself\u001b[39;49m), \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcollate_fn\n\u001b[0;32m    381\u001b[0m         )\n\u001b[0;32m    382\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\dataset_utils.py:382\u001b[0m, in \u001b[0;36mmanage_advanced_indexing\u001b[1;34m(idx, single_element_getter, max_length, collate_fn)\u001b[0m\n\u001b[0;32m    380\u001b[0m elements \u001b[39m=\u001b[39m []\n\u001b[0;32m    381\u001b[0m \u001b[39mfor\u001b[39;00m single_idx \u001b[39min\u001b[39;00m indexes_iterator:\n\u001b[1;32m--> 382\u001b[0m     single_element \u001b[39m=\u001b[39m single_element_getter(\u001b[39mint\u001b[39;49m(single_idx))\n\u001b[0;32m    383\u001b[0m     elements\u001b[39m.\u001b[39mappend(single_element)\n\u001b[0;32m    385\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(elements) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:782\u001b[0m, in \u001b[0;36mAvalancheDataset._get_single_item\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m    781\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_get_single_item\u001b[39m(\u001b[39mself\u001b[39m, idx: \u001b[39mint\u001b[39m):\n\u001b[1;32m--> 782\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_process_pattern(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset[idx], idx)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:789\u001b[0m, in \u001b[0;36mAvalancheDataset._process_pattern\u001b[1;34m(self, element, idx)\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[39mif\u001b[39;00m has_task_label:\n\u001b[0;32m    787\u001b[0m     element \u001b[39m=\u001b[39m element[:\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\n\u001b[1;32m--> 789\u001b[0m element \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_apply_transforms(element)\n\u001b[0;32m    791\u001b[0m \u001b[39mreturn\u001b[39;00m TupleTLabel((\u001b[39m*\u001b[39melement, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtargets_task_labels[idx]))\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\avalanche_dataset.py:808\u001b[0m, in \u001b[0;36mAvalancheDataset._apply_transforms\u001b[1;34m(self, element)\u001b[0m\n\u001b[0;32m    805\u001b[0m     element \u001b[39m=\u001b[39m MultiParamTransform(frozen_group[\u001b[39m0\u001b[39m])(\u001b[39m*\u001b[39melement)\n\u001b[0;32m    807\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransform \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 808\u001b[0m     element \u001b[39m=\u001b[39m MultiParamTransform(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform)(\u001b[39m*\u001b[39;49melement)\n\u001b[0;32m    810\u001b[0m \u001b[39mreturn\u001b[39;00m element\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\adaptive_transform.py:83\u001b[0m, in \u001b[0;36mMultiParamTransform.__call__\u001b[1;34m(self, force_tuple_output, *args)\u001b[0m\n\u001b[0;32m     82\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, force_tuple_output\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[1;32m---> 83\u001b[0m     args \u001b[39m=\u001b[39m MultiParamTransform\u001b[39m.\u001b[39;49m_call_transform(\n\u001b[0;32m     84\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtransform, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmin_params, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_params, \u001b[39m*\u001b[39;49margs\n\u001b[0;32m     85\u001b[0m     )\n\u001b[0;32m     87\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(args) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m force_tuple_output:\n\u001b[0;32m     88\u001b[0m         \u001b[39mreturn\u001b[39;00m args[\u001b[39m0\u001b[39m]  \u001b[39m# Single return value (as an unwrapped value)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\adaptive_transform.py:107\u001b[0m, in \u001b[0;36mMultiParamTransform._call_transform\u001b[1;34m(transform_callable, _, max_par, *params)\u001b[0m\n\u001b[0;32m    104\u001b[0m     n_params \u001b[39m=\u001b[39m \u001b[39mmin\u001b[39m(max_par, \u001b[39mlen\u001b[39m(params))\n\u001b[0;32m    105\u001b[0m params \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(params)\n\u001b[1;32m--> 107\u001b[0m transform_result \u001b[39m=\u001b[39m transform_callable(\u001b[39m*\u001b[39;49mparams[:n_params])\n\u001b[0;32m    108\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(transform_result, \u001b[39mtuple\u001b[39m):\n\u001b[0;32m    109\u001b[0m     transform_result \u001b[39m=\u001b[39m (transform_result,)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001b[0m, in \u001b[0;36mCompose.__call__\u001b[1;34m(self, img)\u001b[0m\n\u001b[0;32m     93\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, img):\n\u001b[0;32m     94\u001b[0m     \u001b[39mfor\u001b[39;00m t \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtransforms:\n\u001b[1;32m---> 95\u001b[0m         img \u001b[39m=\u001b[39m t(img)\n\u001b[0;32m     96\u001b[0m     \u001b[39mreturn\u001b[39;00m img\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torchvision\\transforms\\transforms.py:227\u001b[0m, in \u001b[0;36mToPILImage.__call__\u001b[1;34m(self, pic)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__call__\u001b[39m(\u001b[39mself\u001b[39m, pic):\n\u001b[0;32m    219\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m    220\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m    221\u001b[0m \u001b[39m        pic (Tensor or numpy.ndarray): Image to be converted to PIL Image.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    225\u001b[0m \n\u001b[0;32m    226\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 227\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mto_pil_image(pic, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmode)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torchvision\\transforms\\functional.py:242\u001b[0m, in \u001b[0;36mto_pil_image\u001b[1;34m(pic, mode)\u001b[0m\n\u001b[0;32m    240\u001b[0m     _log_api_usage_once(to_pil_image)\n\u001b[0;32m    241\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39misinstance\u001b[39m(pic, torch\u001b[39m.\u001b[39mTensor) \u001b[39mor\u001b[39;00m \u001b[39misinstance\u001b[39m(pic, np\u001b[39m.\u001b[39mndarray)):\n\u001b[1;32m--> 242\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mpic should be Tensor or ndarray. Got \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(pic)\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    244\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39misinstance\u001b[39m(pic, torch\u001b[39m.\u001b[39mTensor):\n\u001b[0;32m    245\u001b[0m     \u001b[39mif\u001b[39;00m pic\u001b[39m.\u001b[39mndimension() \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m {\u001b[39m2\u001b[39m, \u001b[39m3\u001b[39m}:\n",
      "\u001b[1;31mTypeError\u001b[0m: pic should be Tensor or ndarray. Got <class 'str'>."
     ]
    }
   ],
   "source": [
    "\n",
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
