{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from utils.util import icarl_cifar100_augment_data, get_dataset_per_pixel_mean, get_image_list, dataset_list, PathDataset\n",
    "\n",
    "from avalanche.models import IcarlNet, make_icarl_net, initialize_icarl_net\n",
    "from avalanche.training.supervised import ICaRL\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.datasets import CIFAR10\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.plugins.lr_scheduling import LRSchedulerPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, StreamAccuracy, ExperienceForgetting, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"../Data/CASIA-WebFace/\" \n",
    "\n",
    "dataset = get_image_list(data_path)\n",
    "x_train, x_test, y_train, y_test = train_test_split(dataset[0], dataset[1], test_size=0.2, shuffle=True, random_state=seed, stratify=dataset[1])\n",
    "\n",
    "train_set = dataset_list(x_train, y_train)\n",
    "test_set = dataset_list(x_test, y_test)\n",
    "\n",
    "print(\"train : \", len(y_train))\n",
    "print(\"test : \", len(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pixel_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "# train_per_pixel_mean = get_dataset_per_pixel_mean(train_set, pixel_transforms)\n",
    "# eval_per_pixel_mean = get_dataset_per_pixel_mean(test_set, pixel_transforms)\n",
    "\n",
    "# transforms_group = dict(\n",
    "#        train=(\n",
    "#        transforms.Compose(\n",
    "#               [\n",
    "#               transforms.ToTensor(),\n",
    "#               lambda img_pattern: img_pattern - train_per_pixel_mean,\n",
    "#               icarl_cifar100_augment_data,\n",
    "#               ]\n",
    "#        ),\n",
    "#        None,\n",
    "#        ),\n",
    "#        eval=(\n",
    "#        transforms.Compose(\n",
    "#               [\n",
    "#               transforms.ToTensor(),\n",
    "#               lambda img_pattern: img_pattern - eval_per_pixel_mean,\n",
    "#               ]\n",
    "#        ),\n",
    "#        None,\n",
    "#        )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pixel_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "transforms_group = dict(\n",
    "       train=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              icarl_cifar100_augment_data,\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       ),\n",
    "       eval=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       )\n",
    ")\n",
    "\n",
    "train_set = PathDataset(train_set, transforms_group, \"train\")\n",
    "test_set = PathDataset(test_set, transforms_group, \"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# num_class = 10\n",
    "# incremental = 5\n",
    "# lr_milestones = [49, 63]\n",
    "# lr_factor = 5.0\n",
    "# fixed_class_order = [4, 1, 7, 5, 3, 9, 0, 8, 6, 2]\n",
    "\n",
    "# scenario = nc_benchmark(train_dataset=train_set,\n",
    "#                         test_dataset=test_set,\n",
    "#                         n_experiences=incremental,\n",
    "#                         task_labels=True,\n",
    "#                         seed=seed,\n",
    "#                         shuffle=False,\n",
    "#                         fixed_class_order=fixed_class_order,\n",
    "#                         )\n",
    "\n",
    "# model: IcarlNet = make_icarl_net(num_classes=num_class)\n",
    "# model.apply(initialize_icarl_net)\n",
    "# model.to(device)\n",
    "\n",
    "# optimizer = optim.SGD(model.parameters(), lr=2.0, momentum=0.9, weight_decay=1e-5)\n",
    "# sched = LRSchedulerPlugin(MultiStepLR(optimizer, lr_milestones, gamma=1.0 / lr_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_class = 10575\n",
    "incremental = 5\n",
    "lr_milestones = [49, 63]\n",
    "lr_factor = 5.0\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=True,\n",
    "                        seed=seed,\n",
    "                        shuffle=False\n",
    "                        )\n",
    "\n",
    "model: IcarlNet = make_icarl_net(num_classes=num_class)\n",
    "model.apply(initialize_icarl_net)\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=2.0, momentum=0.9, weight_decay=1e-5)\n",
    "sched = LRSchedulerPlugin(MultiStepLR(optimizer, lr_milestones, gamma=1.0 / lr_factor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(project_name=\"Face Recognition\", run_name=\"iCaRL-CASIA-M2000-test\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceTime(),\n",
    "    StreamAccuracy(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_size = 2000\n",
    "train_batch = 10\n",
    "eval_batch = 1\n",
    "epoch = 10\n",
    "\n",
    "buffer_transform = transforms.Compose([icarl_cifar100_augment_data])\n",
    "\n",
    "strategies = ICaRL(model.feature_extractor, model.classifier, optimizer, memory_size, buffer_transform=buffer_transform, fixed_memory=True, train_mb_size=train_batch, train_epochs=epoch, eval_mb_size=eval_batch, device=device, plugins=[sched], evaluator=eval_plugin)  # criterion = ICaRLLossPlugin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
