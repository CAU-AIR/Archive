{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN and NCM for MNIST feature extraction and classification\n",
    "### Summary\n",
    "MNIST 데이터셋을 분류하기 위해 먼저 CNN을 Pretraining 시킨 후, FC layer만 제거하여 Feature Extractor로 활용.\n",
    "\n",
    "CNN으로 추출된 feature를 NCM의 데이터로 사용.\n",
    "\n",
    "기존 CNN Test Accuracy : 약 98.5% \n",
    "\n",
    "CNN + NCM : 약 93.7% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils.utils import Info\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from utils.NCM_Classifier import train, validate\n",
    "from models.resnet_feature import resnet18_feature\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from utils.Data_Classifier import accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(Info):\n",
    "    def __init__(self):\n",
    "        super(Info, self).__init__()\n",
    "        self.device = 'PC'\n",
    "        self.dataset = 'MNIST'\n",
    "        self.test_size = 0.2\n",
    "        self.feature_size = 3072\n",
    "        self.method = 'NCM'\n",
    "        self.distance = 'Euclidean'\n",
    "        self.reduction_method = [None, None] # method, n_components\n",
    "        self.iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────MNIST\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────NCM\n",
      "│    └────Euclidean\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: None\n",
      "│    └────Component size: None\n",
      "│    └────Feature Reduction Ratio: None%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n",
      "PC - MNIST(80%) - NCM - 10 iteration\n"
     ]
    }
   ],
   "source": [
    "cig = Config()\n",
    "cig.info()\n",
    "cig.print_rutin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([60000, 28, 28])\n",
      "torch.Size([10000, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.5,), (1.0,))\n",
    "                                ])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='../../datasets', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "validationset = torchvision.datasets.MNIST(root='../../datasets', train=False, download=True, transform=transform)\n",
    "val_loader = DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "print(validationset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pretraining CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3)\n",
    "        self.conv2 = nn.Conv2d(16, 32, 3)\n",
    "        self.conv3 = nn.Conv2d(32, 64, 3)\n",
    "\n",
    "        self.maxpool = nn.MaxPool2d(kernel_size=3, stride=2, padding=1)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.fc = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x): # 28 x 28\n",
    "        x = self.conv1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) # 14 x 14\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) # 7 x 7\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.maxpool(x) # 4 x 4\n",
    "\n",
    "        x = self.avgpool(x) # 1 x 1\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "총 배치의 수 : 118, 20\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=64, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate = 0.001\n",
    "training_epochs = 15\n",
    "batch_size = 100\n",
    "\n",
    "net = CNN().to(device)\n",
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()  # 비용 함수에 소프트맥스 함수 포함되어져 있음.\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "\n",
    "total_train_batch = len(train_loader)\n",
    "total_test_batch = len(val_loader)\n",
    "print('총 배치의 수 : {}, {}'.format(total_train_batch, total_test_batch))\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch:    1] Acc : 61.57198715209961 cost : 1.34405637\n",
      "Test Acc: 88.96599578857422\n",
      "[Epoch:    2] Acc : 91.71138000488281 cost : 0.29286927\n",
      "Test Acc: 93.60466766357422\n",
      "[Epoch:    3] Acc : 94.4644775390625 cost : 0.185504705\n",
      "Test Acc: 95.91107177734375\n",
      "[Epoch:    4] Acc : 95.72738647460938 cost : 0.142004624\n",
      "Test Acc: 96.11845397949219\n",
      "[Epoch:    5] Acc : 96.37627410888672 cost : 0.11929287\n",
      "Test Acc: 96.97552490234375\n",
      "[Epoch:    6] Acc : 96.79668426513672 cost : 0.104789771\n",
      "Test Acc: 97.41153717041016\n",
      "[Epoch:    7] Acc : 97.20166015625 cost : 0.0904851854\n",
      "Test Acc: 97.34432220458984\n",
      "[Epoch:    8] Acc : 97.50676727294922 cost : 0.0803703144\n",
      "Test Acc: 97.90613555908203\n",
      "[Epoch:    9] Acc : 97.74124145507812 cost : 0.0732725561\n",
      "Test Acc: 97.97449493408203\n",
      "[Epoch:   10] Acc : 97.86259460449219 cost : 0.0690031052\n",
      "Test Acc: 98.26861572265625\n",
      "[Epoch:   11] Acc : 98.06503295898438 cost : 0.0630972534\n",
      "Test Acc: 98.29905700683594\n",
      "[Epoch:   12] Acc : 98.2349853515625 cost : 0.0581942722\n",
      "Test Acc: 98.37373352050781\n",
      "[Epoch:   13] Acc : 98.36075592041016 cost : 0.054112684\n",
      "Test Acc: 98.32950592041016\n",
      "[Epoch:   14] Acc : 98.4495620727539 cost : 0.0511797294\n",
      "Test Acc: 98.50183868408203\n",
      "[Epoch:   15] Acc : 98.48545837402344 cost : 0.0493449643\n",
      "Test Acc: 98.45760345458984\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    avg_cost = 0\n",
    "    avg_train_acc = 0\n",
    "    avg_test_acc = 0\n",
    "\n",
    "    net.train()\n",
    "    for X, Y in train_loader: # 미니 배치 단위로 꺼내온다. X는 미니 배치, Y느 ㄴ레이블.\n",
    "        # image is already size of (28x28), no reshape\n",
    "        # label is not one-hot encoded\n",
    "        X = X.to(device)\n",
    "        Y = Y.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        hypothesis = net(X)\n",
    "        cost = criterion(hypothesis, Y)\n",
    "        acc = accuracy(hypothesis, Y)\n",
    "\n",
    "        cost.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        avg_cost += cost / total_train_batch\n",
    "        avg_train_acc += acc / total_train_batch\n",
    "\n",
    "    print('[Epoch: {:>4}] Acc : {:>4} cost : {:>.9}'.format(epoch + 1, avg_train_acc.item(), avg_cost.item()))\n",
    "\n",
    "    net.eval()\n",
    "    with torch.no_grad():\n",
    "        for X_test, Y_test in val_loader:\n",
    "            X_test = X_test.to(device)\n",
    "            Y_test = Y_test.to(device)\n",
    "\n",
    "            prediction = net(X_test)\n",
    "\n",
    "            acc = accuracy(prediction, Y_test)\n",
    "            avg_test_acc += acc / total_test_batch\n",
    "\n",
    "    print('Test Acc: {:>4}'.format(avg_test_acc.item()) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 64 Feature Extrator (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNN(\n",
       "  (conv1): Conv2d(1, 16, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv2): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "net.fc = Identity()\n",
    "net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Fit\n",
      "\n",
      "Train Data Feature Extract Time : 4.2274 sec\n",
      "Train Data Fitting NCM Time : 0.0140 sec\n",
      "\n",
      "Train Accuracy : 93.16 %\n"
     ]
    }
   ],
   "source": [
    "# NCM\n",
    "classifier = NearestCentroid()\n",
    "\n",
    "net.eval()\n",
    "\n",
    "features = []\n",
    "targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for i, (images, target) in enumerate(train_loader):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "        # compute output\n",
    "        feature = net(images)\n",
    "        features.extend(feature.cpu().numpy())\n",
    "        targets.extend(target.cpu().numpy())\n",
    "    feature_extract_time = time.time() - start_time\n",
    "\n",
    "    features = np.array(features)\n",
    "    targets = np.array(targets)\n",
    "\n",
    "    c_start_time = time.time()\n",
    "    classifier.fit(features, targets)\n",
    "    fit_time = time.time() - c_start_time\n",
    "    output = classifier.predict(features)\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    acc = accuracy_score(output, targets)\n",
    "\n",
    "print('\\nFinished Fit\\n')\n",
    "print(\"Train Data Feature Extract Time : %.4f\" % feature_extract_time, \"sec\")\n",
    "print(\"Train Data Fitting NCM Time : %.4f\" % fit_time, \"sec\")\n",
    "print(\"\\nTrain Accuracy : %.2f\" % (acc*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Predicting\n",
      "\n",
      "Test Data Feature Extract Time : 1.4511 sec\n",
      "Test Data Prediction Time : 0.0030 sec\n",
      "\n",
      "Test Accuracy : 93.74 %\n"
     ]
    }
   ],
   "source": [
    "net.eval()\n",
    "\n",
    "test_features = []\n",
    "test_targets = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    start_time = time.time()\n",
    "    for i, (images, target) in enumerate(val_loader):\n",
    "\n",
    "        if torch.cuda.is_available():\n",
    "            images = images.to(device)\n",
    "            target = target.to(device)\n",
    "\n",
    "        # compute output\n",
    "        feature = net(images)\n",
    "        test_features.extend(feature.cpu().numpy())\n",
    "        test_targets.extend(target.cpu().numpy())\n",
    "    feature_extract_time = time.time() - start_time\n",
    "\n",
    "    test_features = np.array(test_features)\n",
    "    test_targets = np.array(test_targets)\n",
    "\n",
    "    c_start_time = time.time()\n",
    "    output = classifier.predict(test_features)\n",
    "    predict_time = time.time() - c_start_time\n",
    "\n",
    "    # measure accuracy and record loss\n",
    "    acc = accuracy_score(output, test_targets)\n",
    "\n",
    "\n",
    "print('\\nFinished Predicting\\n')\n",
    "print(\"Test Data Feature Extract Time : %.4f\" % feature_extract_time, \"sec\")\n",
    "print(\"Test Data Prediction Time : %.4f\" % predict_time, \"sec\")\n",
    "print(\"\\nTest Accuracy : %.2f\" % (acc*100), \"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96617a4ccdf4ff8af9cb4fdc6a0e520bbd799675b4cf9420cbe414d64a946884"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
