{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using PCA and NCM for MNIST feature extraction and classification\n",
    "### Summary\n",
    "MNIST 데이터셋을 분류하기 위해 PCA로 feature 추출 후 NCM으로 분류.\n",
    "\n",
    "기존 CNN Test Accuracy : 약 98.5% \n",
    "\n",
    "CNN + NCM : 약 93.7% "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "from sklearn.datasets import fetch_openml\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision\n",
    "from torchvision.datasets import MNIST\n",
    "from torchvision import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseConfig:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def info(self):\n",
    "        config_list = {\n",
    "            0 : ['Dataset', self.dataset, \n",
    "                 \"Train size: \" + str(int((1-self.test_size)*100))+\"%\",\n",
    "                 'Feature size: ' + str(self.feature_size), 1],\n",
    "            1 : ['Method', self.method, \n",
    "                 \"k = \" + str(self.k), self.distance, 2],\n",
    "            2 : ['Dimension reduction', \n",
    "                 'Method: ' + str(self.reduction_method[0]),\n",
    "                 'Component size: ' + str(self.reduction_method[1]),\n",
    "                 'Feature Reduction Ratio: ' + \\\n",
    "                    str(round(self.reduction_method[1]/self.feature_size, 3)*100 if self.reduction_method[1] is not None else None)+\"%\", 3],\n",
    "            3 : ['Iteration', str(self.iter), -1]\n",
    "        }\n",
    "\n",
    "        print(\"Device \" + \"─\" * 2 + \" \" + self.device)\n",
    "        print(\"│\")\n",
    "\n",
    "        parent = 1\n",
    "        for child in range(len(config_list)):\n",
    "            for idx, contents in enumerate(config_list[child][:-1]):\n",
    "                if idx == 0 and child == len(config_list)-1:\n",
    "                    print(\"└\" + \"─\" * 2 + contents)\n",
    "                elif idx == 0:\n",
    "                    print(\"├\" + \"─\" * 2 + contents)\n",
    "                elif child == len(config_list)-1:\n",
    "                    print(\" \" * 4 + \"└\" + \"─\" * 4 + contents)\n",
    "                else:\n",
    "                    print(\"│\" + \" \" * 4 + \"└\" + \"─\" * 4 + contents)\n",
    "            parent = config_list[child][-1]\n",
    "            if parent == -1: break\n",
    "            print(\"│\")\n",
    "\n",
    "class Config(BaseConfig):\n",
    "    def __init__(self):\n",
    "        super(BaseConfig, self).__init__()\n",
    "        self.device = 'PC'\n",
    "        self.dataset = 'Mnist'\n",
    "        self.test_size = 0.2\n",
    "        self.feature_size = 784\n",
    "        self.method = 'NCM'\n",
    "        self.k = None\n",
    "        self.distance = 'Euclidean'\n",
    "        self.reduction_method = [None, None] # method, n_components\n",
    "        self.iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Cau_13\\Anaconda3\\envs\\tf-venv\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "train_mnist = MNIST(root='../../datasets', train=True, download=False)\n",
    "test_mnist = MNIST(root='../../datasets', train=False, download=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data X shape : (60000, 28, 28), y shape : (60000,)\n",
      "Test data X shape : (10000, 28, 28), y shape : (10000,)\n"
     ]
    }
   ],
   "source": [
    "train_mnist_X, train_mnist_y = train_mnist.data.numpy(), train_mnist.targets.numpy()\n",
    "test_mnist_X, test_mnist_y = test_mnist.data.numpy(), test_mnist.targets.numpy()\n",
    "\n",
    "print(f'Train data X shape : {train_mnist_X.shape}, y shape : {train_mnist_y.shape}')\n",
    "print(f'Test data X shape : {test_mnist_X.shape}, y shape : {test_mnist_y.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist Data range [0, 255] \n",
      "--> Mnist Data Normalized range [0.0, 1.0] \n"
     ]
    }
   ],
   "source": [
    "print(f'Mnist Data range [{train_mnist_X.min()}, {train_mnist_X.max()}] ')\n",
    "\n",
    "train_mnist_X, test_mnist_X = train_mnist_X / 255., test_mnist_X / 255.\n",
    "\n",
    "print(f'--> Mnist Data Normalized range [{train_mnist_X.min()}, {train_mnist_X.max()}] ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mnist Data shape train : (60000, 28, 28), test : (10000, 28, 28)\n",
      "--> Mnist Data shape train : (60000, 784), test : (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(f'Mnist Data shape train : {train_mnist_X.shape}, test : {test_mnist_X.shape}')\n",
    "\n",
    "train_mnist_X = train_mnist_X.reshape(-1, 784)\n",
    "test_mnist_X = test_mnist_X.reshape(-1, 784)\n",
    "\n",
    "print(f'--> Mnist Data shape train : {train_mnist_X.shape}, test : {test_mnist_X.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────Mnist\n",
      "│    └────Train size: 80%\n",
      "│    └────Feature size: 784\n",
      "│\n",
      "├──Method\n",
      "│    └────NCM\n",
      "│    └────k = None\n",
      "│    └────Euclidean\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: None\n",
      "│    └────Component size: None\n",
      "│    └────Feature Reduction Ratio: None%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "config = Config()\n",
    "config.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NCM_run(train_data_X = train_mnist_X,\n",
    "            train_data_y = train_mnist_y,\n",
    "            test_data_X = test_mnist_X,\n",
    "            test_data_y = test_mnist_y,\n",
    "            config = None,\n",
    "            weights = 'distance'):\n",
    "\n",
    "    assert config is not None\n",
    "    config.info()\n",
    "    max_seed = config.iter\n",
    "\n",
    "    avg_test_acc = []\n",
    "    avg_ncm_fit_time = []\n",
    "    avg_pred_time = []\n",
    "    preds = []\n",
    "\n",
    "    for seed in tqdm(range(max_seed)):\n",
    "        x_train, x_test, y_train, y_test = train_data_X, test_data_X, train_data_y, test_data_y\n",
    "\n",
    "        ncm = NearestCentroid()\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        ncm.fit(x_train, y_train)\n",
    "        ncm_fit_time = time.perf_counter() - start_time\n",
    "        avg_ncm_fit_time.append(ncm_fit_time)\n",
    "\n",
    "        start_time = time.perf_counter()\n",
    "        pred = ncm.predict(x_test)\n",
    "        pred_time = time.perf_counter() - start_time\n",
    "        preds.append(pred)\n",
    "\n",
    "        test_score = accuracy_score(pred, y_test)\n",
    "        avg_test_acc.append(test_score)\n",
    "        avg_pred_time.append(pred_time)\n",
    "\n",
    "    print(\"Train size : \", len(x_train), \" / Test size : \", len(x_test))\n",
    "    print(\"-----\" * 8)\n",
    "    print(\"Test set score: %f\" % np.array(avg_test_acc).mean())\n",
    "    print(\"NCM fitting Time: %.4f ± %.5f\" % (np.array(avg_ncm_fit_time).mean(), np.array(avg_ncm_fit_time).std()), \"sec\")\n",
    "    print(\"All Test dataset Prediction Time at once : %.4f ± %.5f\" % (np.array(avg_pred_time).mean(), np.array(avg_pred_time).std()), \"sec\")\n",
    "    print(\"Divide the Prediction Time by Test size : %.8f ± %.8f\" % (np.array(avg_pred_time).mean()/len(x_test)*1e6, np.array(avg_pred_time).std()/len(x_test)*1e6), \"microsec\")\n",
    "\n",
    "    return avg_test_acc, avg_ncm_fit_time, avg_pred_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pca_run(train_data_X = train_mnist_X,\n",
    "            test_data_X = test_mnist_X,\n",
    "            config=None):\n",
    "\n",
    "    assert config is not None\n",
    "    config.info()\n",
    "\n",
    "    n_components = config.reduction_method[1]\n",
    "\n",
    "    pca_dims = PCA(n_components)\n",
    "    print(f\"The number of components : {n_components}\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    pca_dims.fit(train_data_X)\n",
    "    pca_fit_time = time.perf_counter () - start_time\n",
    "    print()\n",
    "    print(f\"Calculating SVD Matrix Time on Train Data-{train_data_X.shape} : {pca_fit_time:4f} sec\")\n",
    "    \n",
    "    start_time = time.perf_counter()\n",
    "    train_features = pca_dims.transform(train_data_X)\n",
    "    train_features_extract_time = time.perf_counter () - start_time\n",
    "    print(f\"Transform train X-{train_data_X.shape} to {n_components}-PCA Time: {train_features_extract_time:4f} sec\")\n",
    "\n",
    "    start_time = time.perf_counter()\n",
    "    test_features = pca_dims.transform(test_data_X)\n",
    "    test_features_extract_time = time.perf_counter () - start_time\n",
    "    print(f\"Transform test X-{train_data_X.shape} to {n_components}-PCA Time: {test_features_extract_time:4f} sec\")\n",
    "\n",
    "    return pca_dims, train_features, test_features, pca_fit_time, train_features_extract_time, test_features_extract_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_components_list = []\n",
    "pca_fit_time_list = []\n",
    "train_features_extract_time_list = []\n",
    "test_features_extract_time_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────Mnist\n",
      "│    └────Train size: 80%\n",
      "│    └────Feature size: 784\n",
      "│\n",
      "├──Method\n",
      "│    └────NCM\n",
      "│    └────k = None\n",
      "│    └────Euclidean\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: PCA\n",
      "│    └────Component size: 64\n",
      "│    └────Feature Reduction Ratio: 8.200000000000001%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n",
      "The number of components : 64\n",
      "\n",
      "Calculating SVD Matrix Time on Train Data-(60000, 784) : 1.922037 sec\n",
      "Transform train X-(60000, 784) to 64-PCA Time: 0.252412 sec\n",
      "Transform test X-(60000, 784) to 64-PCA Time: 0.062013 sec\n"
     ]
    }
   ],
   "source": [
    "config.reduction_method = ['PCA', 64]\n",
    "\n",
    "pca_dims, train_features, test_features, pca_fit_time, train_features_extract_time, test_features_extract_time = \\\n",
    "    pca_run(train_data_X = train_mnist_X,\n",
    "            test_data_X = test_mnist_X,\n",
    "            config=config)\n",
    "\n",
    "n_components_list.append(config.reduction_method[1])\n",
    "pca_fit_time_list.append(pca_fit_time)\n",
    "train_features_extract_time_list.append(train_features_extract_time)\n",
    "test_features_extract_time_list.append(test_features_extract_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────Mnist\n",
      "│    └────Train size: 80%\n",
      "│    └────Feature size: 784\n",
      "│\n",
      "├──Method\n",
      "│    └────NCM\n",
      "│    └────k = None\n",
      "│    └────Euclidean\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: PCA\n",
      "│    └────Component size: 64\n",
      "│    └────Feature Reduction Ratio: 8.200000000000001%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 29.83it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size :  60000  / Test size :  10000\n",
      "----------------------------------------\n",
      "Test set score: 0.818100\n",
      "NCM fitting Time: 0.0286 ± 0.00193 sec\n",
      "All Test dataset Prediction Time at once : 0.0041 ± 0.00161 sec\n",
      "Divide the Prediction Time by Test size : 0.40941700 ± 0.16129807 microsec\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "avg_test_acc, avg_knn_fit_time, avg_pred_time = NCM_run(train_data_X = train_features,\n",
    "                                                        train_data_y = train_mnist_y,\n",
    "                                                        test_data_X = test_features,\n",
    "                                                        test_data_y = test_mnist_y,\n",
    "                                                        config = config,\n",
    "                                                        weights = 'distance')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "96617a4ccdf4ff8af9cb4fdc6a0e520bbd799675b4cf9420cbe414d64a946884"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('tf-venv')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
