{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from utils.util import icarl_cifar100_augment_data, get_dataset_per_pixel_mean\n",
    "\n",
    "from avalanche.models import IcarlNet\n",
    "from avalanche.training.strategies import ICaRL\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.datasets import CIFAR10\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.plugins.lr_scheduling import LRSchedulerPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "pixel_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "per_pixel_mean = get_dataset_per_pixel_mean(CIFAR10('../data', train=True, download=True, transform=pixel_transforms))\n",
    "\n",
    "transforms_group = dict(\n",
    "       train=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              lambda img_pattern: img_pattern - per_pixel_mean,\n",
    "              icarl_cifar100_augment_data,\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       ),\n",
    "       eval=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              lambda img_pattern: img_pattern - per_pixel_mean,\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       )\n",
    ")\n",
    "\n",
    "train_set = CIFAR10('../data', train=True, download=True)\n",
    "test_set = CIFAR10('../data', train=False, download=True)\n",
    "\n",
    "train_set = AvalancheDataset(train_set, transform_groups=transforms_group, initial_transform_group=\"train\")\n",
    "test_set = AvalancheDataset(test_set, transform_groups=transforms_group, initial_transform_group=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_transform=transforms.Compose([transforms.ToTensor(),\n",
    "#                           lambda img_pattern: img_pattern - per_pixel_mean,\n",
    "#                           icarl_cifar100_augment_data])\n",
    "\n",
    "# eval_transform=transforms.Compose([transforms.ToTensor(),\n",
    "#                           lambda img_pattern: img_pattern - per_pixel_mean])\n",
    "\n",
    "# splitcifar = SplitCIFAR10(n_experiences=5, seed=seed, train_transform=train_transform, eval_transform=eval_transform, dataset_root='../data')\n",
    "\n",
    "# train_set = splitcifar.train_stream\n",
    "# test_set = splitcifar.test_stream\n",
    "\n",
    "# print(splitcifar.classes_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mhopo55\u001b[0m (use `wandb login --relogin` to force relogin)\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hopo55/Avalanche/runs/cee4sj7e\" target=\"_blank\">Test</a></strong> to <a href=\"https://wandb.ai/hopo55/Avalanche\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\plugins\\evaluation.py:84: UserWarning: No benchmark provided to the evaluation plugin. Metrics may be computed on inconsistent portion of streams, use at your own risk.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger()\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_class = 10\n",
    "incremental = 5\n",
    "lr_milestones = [49, 63]\n",
    "lr_factor = 5.0\n",
    "fixed_class_order = [4, 1, 7, 5, 3, 9, 0, 8, 6, 2]\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=True,\n",
    "                        seed=seed,\n",
    "                        shuffle=False,\n",
    "                        fixed_class_order=fixed_class_order,\n",
    "                        )\n",
    "\n",
    "model = IcarlNet(num_classes=num_class)    # n = ResidualBlock, c = input_dim\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=2.0, momentum=0.9, weight_decay=1e-5)\n",
    "sched = LRSchedulerPlugin(\n",
    "        MultiStepLR(optimizer, lr_milestones, gamma=1.0 / lr_factor)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pllugins :  [<avalanche.training.plugins.lr_scheduling.LRSchedulerPlugin object at 0x000001FF26150EE0>, <avalanche.training.strategies.icarl._ICaRLPlugin object at 0x000001FF260FC130>, <avalanche.training.losses.ICaRLLossPlugin object at 0x000001FF2457DE20>, <avalanche.training.plugins.evaluation.EvaluationPlugin object at 0x000001FF260FC1F0>]\n"
     ]
    }
   ],
   "source": [
    "memory_size = 2000\n",
    "train_batch = 64\n",
    "eval_batch = 32\n",
    "epoch = 70\n",
    "\n",
    "buffer_transform = transforms.Compose([icarl_cifar100_augment_data])\n",
    "\n",
    "strategies = ICaRL(model.feature_extractor, model.classifier, optimizer, memory_size, buffer_transform=buffer_transform, fixed_memory=True, train_mb_size=train_batch, train_epochs=epoch, eval_mb_size=eval_batch, device=device, plugins=[sched], evaluator=eval_plugin)  # criterion = ICaRLLossPlugin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_stream = scenario.train_stream\n",
    "# test_stream = scenario.test_stream\n",
    "\n",
    "# for idx, experience in enumerate(train_stream):\n",
    "#     dataset = experience.dataset\n",
    "    \n",
    "#     print('Train dataset contains', len(dataset), 'patterns')\n",
    "\n",
    "#     for x, y, task_label in dataset:\n",
    "#         # Train Step...\n",
    "#         strategies.train(x, num_workers=4)\n",
    "    \n",
    "#     test_experience = test_stream[idx]\n",
    "#     strategies.eval(eval_exps, num_workers=4)\n",
    "\n",
    "#     cumulative_test = test_stream[:idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 0 (Task 0) from train stream --\n",
      "100%|██████████| 157/157 [00:07<00:00, 20.86it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5032\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.10it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:05<00:00, 31.32it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:05<00:00, 31.14it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.60it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.87it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.23it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.43it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.24it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.54it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.62it/s]\n",
      "Epoch 10 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.79it/s]\n",
      "Epoch 11 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.93it/s]\n",
      "Epoch 12 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.71it/s]\n",
      "Epoch 13 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.67it/s]\n",
      "Epoch 14 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.52it/s]\n",
      "Epoch 15 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.98it/s]\n",
      "Epoch 16 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.84it/s]\n",
      "Epoch 17 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.00it/s]\n",
      "Epoch 18 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.76it/s]\n",
      "Epoch 19 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.41it/s]\n",
      "Epoch 20 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.66it/s]\n",
      "Epoch 21 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.81it/s]\n",
      "Epoch 22 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.71it/s]\n",
      "Epoch 23 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.49it/s]\n",
      "Epoch 24 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.82it/s]\n",
      "Epoch 25 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.75it/s]\n",
      "Epoch 26 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.40it/s]\n",
      "Epoch 27 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.68it/s]\n",
      "Epoch 28 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.68it/s]\n",
      "Epoch 29 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.44it/s]\n",
      "Epoch 30 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.94it/s]\n",
      "Epoch 31 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.70it/s]\n",
      "Epoch 32 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.41it/s]\n",
      "Epoch 33 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.34it/s]\n",
      "Epoch 34 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.72it/s]\n",
      "Epoch 35 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 31.72it/s]\n",
      "Epoch 36 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.01it/s]\n",
      "Epoch 37 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.37it/s]\n",
      "Epoch 38 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.83it/s]\n",
      "Epoch 39 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.39it/s]\n",
      "Epoch 40 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.48it/s]\n",
      "Epoch 41 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.47it/s]\n",
      "Epoch 42 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.52it/s]\n",
      "Epoch 43 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.05it/s]\n",
      "Epoch 44 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.98it/s]\n",
      "Epoch 45 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.5000\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.49it/s]\n",
      "Epoch 46 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.4710\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.64it/s]\n",
      "Epoch 47 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.7314\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.21it/s]\n",
      "Epoch 48 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8520\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.91it/s]\n",
      "Epoch 49 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9060\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.53it/s]\n",
      "Epoch 50 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9090\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.54it/s]\n",
      "Epoch 51 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9135\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.79it/s]\n",
      "Epoch 52 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9133\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.37it/s]\n",
      "Epoch 53 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9185\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.37it/s]\n",
      "Epoch 54 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9184\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.23it/s]\n",
      "Epoch 55 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9200\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.17it/s]\n",
      "Epoch 56 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9208\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.51it/s]\n",
      "Epoch 57 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9237\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.54it/s]\n",
      "Epoch 58 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9288\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.83it/s]\n",
      "Epoch 59 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9292\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.24it/s]\n",
      "Epoch 60 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9309\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.60it/s]\n",
      "Epoch 61 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9288\n",
      "100%|██████████| 157/157 [00:04<00:00, 32.16it/s]\n",
      "Epoch 62 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9310\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.65it/s]\n",
      "Epoch 63 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9369\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.26it/s]\n",
      "Epoch 64 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9378\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.31it/s]\n",
      "Epoch 65 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9380\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.11it/s]\n",
      "Epoch 66 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9399\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.30it/s]\n",
      "Epoch 67 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9426\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.45it/s]\n",
      "Epoch 68 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9395\n",
      "100%|██████████| 157/157 [00:04<00:00, 33.55it/s]\n",
      "Epoch 69 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.9402\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    # strategies.train_exp(exp, eval_exps)\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)\n",
    "    # res = strategies.train_exp(exp, eval_exps)\n",
    "    # print(res)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
