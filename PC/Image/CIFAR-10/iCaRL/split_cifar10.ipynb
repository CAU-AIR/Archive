{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "from torch.optim.lr_scheduler import MultiStepLR\n",
    "from utils.util import icarl_cifar100_augment_data, get_dataset_per_pixel_mean\n",
    "\n",
    "from avalanche.models import IcarlNet\n",
    "from avalanche.training.strategies import ICaRL\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.datasets import CIFAR10\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.training.plugins.lr_scheduling import LRSchedulerPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "pixel_transforms = transforms.Compose([transforms.ToTensor()])\n",
    "per_pixel_mean = get_dataset_per_pixel_mean(CIFAR10('../data', train=True, download=True, transform=pixel_transforms))\n",
    "\n",
    "transforms_group = dict(\n",
    "       train=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              lambda img_pattern: img_pattern - per_pixel_mean,\n",
    "              icarl_cifar100_augment_data,\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       ),\n",
    "       eval=(\n",
    "       transforms.Compose(\n",
    "              [\n",
    "              transforms.ToTensor(),\n",
    "              lambda img_pattern: img_pattern - per_pixel_mean,\n",
    "              ]\n",
    "       ),\n",
    "       None,\n",
    "       )\n",
    ")\n",
    "\n",
    "train_set = CIFAR10('../data', train=True, download=True)\n",
    "test_set = CIFAR10('../data', train=False, download=True)\n",
    "\n",
    "train_set = AvalancheDataset(train_set, transform_groups=transforms_group, initial_transform_group=\"train\")\n",
    "test_set = AvalancheDataset(test_set, transform_groups=transforms_group, initial_transform_group=\"eval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitcifar = SplitCIFAR10(n_experiences=5, seed=seed, dataset_root='../data')\n",
    "\n",
    "# train_stream = splitcifar.train_stream\n",
    "# test_stream = splitcifar.test_stream\n",
    "\n",
    "# print(splitcifar.classes_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_class = 10\n",
    "incremental = 2\n",
    "lr_milestones = [49, 63]    # ?\n",
    "lr_factor = 5.0 # ?\n",
    "fixed_class_order = [4, 1, 7, 5, 3, 9, 0, 8, 6, 2]\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=True,\n",
    "                        seed=seed,\n",
    "                        shuffle=False,\n",
    "                        fixed_class_order=fixed_class_order,\n",
    "                        )\n",
    "\n",
    "model = IcarlNet(num_classes=num_class)    # n = ResidualBlock, c = input_dim\n",
    "model.to(device)\n",
    "\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "sched = LRSchedulerPlugin(\n",
    "        MultiStepLR(optimizer, lr_milestones, gamma=1.0 / lr_factor)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "memory_size = 2000\n",
    "train_batch = 128\n",
    "eval_batch = 64\n",
    "epoch = 10\n",
    "\n",
    "buffer_transform = transforms.Compose([icarl_cifar100_augment_data])\n",
    "\n",
    "strategies = ICaRL(model.feature_extractor, model.classifier, optimizer, memory_size, buffer_transform=buffer_transform, fixed_memory=True, train_mb_size=train_batch, train_epochs=epoch, eval_mb_size=eval_batch, device=device, plugins=[sched], evaluator=eval_plugin)  # criterion = ICaRLLossPlugin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset contains 25000 patterns\n",
      "Train dataset contains 25000 patterns\n"
     ]
    }
   ],
   "source": [
    "train_stream = scenario.train_stream\n",
    "test_stream = scenario.test_stream\n",
    "\n",
    "for idx, experience in enumerate(train_stream):\n",
    "    dataset = experience.dataset\n",
    "    \n",
    "    print('Train dataset contains', len(dataset), 'patterns')\n",
    "\n",
    "    for x, y, task_label in dataset:\n",
    "        # Train Step...\n",
    "        pass\n",
    "    \n",
    "    test_experience = test_stream[idx]\n",
    "    cumulative_test = test_stream[:idx+1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 0 (Task 0) from train stream --\n"
     ]
    },
    {
     "ename": "PicklingError",
     "evalue": "Can't pickle <function <lambda> at 0x000001B8AF9EAC10>: attribute lookup <lambda> on __main__ failed",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPicklingError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LAB\\Desktop\\Archive\\PC\\Image\\CIFAR-10\\iCaRL\\split_cifar10.ipynb Cell 9'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/iCaRL/split_cifar10.ipynb#ch0000007?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, exp \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(scenario\u001b[39m.\u001b[39mtrain_stream):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/iCaRL/split_cifar10.ipynb#ch0000007?line=1'>2</a>\u001b[0m     eval_exps \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m scenario\u001b[39m.\u001b[39mtest_stream][: i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/iCaRL/split_cifar10.ipynb#ch0000007?line=2'>3</a>\u001b[0m     strategies\u001b[39m.\u001b[39;49mtrain(exp, num_workers\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/iCaRL/split_cifar10.ipynb#ch0000007?line=3'>4</a>\u001b[0m     strategies\u001b[39m.\u001b[39meval(eval_exps, num_workers\u001b[39m=\u001b[39m\u001b[39m4\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\base_strategy.py:280\u001b[0m, in \u001b[0;36mBaseStrategy.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=276'>277</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_periodic_eval(eval_streams, do_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, do_initial\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=278'>279</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperience \u001b[39min\u001b[39;00m experiences:\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=279'>280</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_exp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperience, eval_streams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=280'>281</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtrain_exp\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=282'>283</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\base_strategy.py:333\u001b[0m, in \u001b[0;36mBaseStrategy.train_exp\u001b[1;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=329'>330</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=330'>331</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=332'>333</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_epoch(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=333'>334</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mtraining_epoch\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=334'>335</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training_epoch(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\base_strategy.py:505\u001b[0m, in \u001b[0;36mBaseStrategy.training_epoch\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=498'>499</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtraining_epoch\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=499'>500</a>\u001b[0m     \u001b[39m\"\"\" Training epoch.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=500'>501</a>\u001b[0m \u001b[39m    \u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=501'>502</a>\u001b[0m \u001b[39m    :param kwargs:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=502'>503</a>\u001b[0m \u001b[39m    :return:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=503'>504</a>\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=504'>505</a>\u001b[0m     \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmbatch \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloader:\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=505'>506</a>\u001b[0m     \u001b[39m# for _ in self.dataloader:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=506'>507</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mself.mbatch : \u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmbatch)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=508'>509</a>\u001b[0m         \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mstart mbatch\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\data_loader.py:92\u001b[0m, in \u001b[0;36mTaskBalancedDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=90'>91</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__iter__\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[1;32m---> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=91'>92</a>\u001b[0m     \u001b[39mfor\u001b[39;00m el \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dl\u001b[39m.\u001b[39m\u001b[39m__iter__\u001b[39m():\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=92'>93</a>\u001b[0m         \u001b[39myield\u001b[39;00m el\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\benchmarks\\utils\\data_loader.py:137\u001b[0m, in \u001b[0;36mGroupBalancedDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=134'>135</a>\u001b[0m iter_dataloaders \u001b[39m=\u001b[39m []\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=135'>136</a>\u001b[0m \u001b[39mfor\u001b[39;00m dl \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataloaders:\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=136'>137</a>\u001b[0m     iter_dataloaders\u001b[39m.\u001b[39mappend(\u001b[39miter\u001b[39;49m(dl))\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=138'>139</a>\u001b[0m max_num_mbatches \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m([\u001b[39mlen\u001b[39m(d) \u001b[39mfor\u001b[39;00m d \u001b[39min\u001b[39;00m iter_dataloaders])\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/benchmarks/utils/data_loader.py?line=139'>140</a>\u001b[0m \u001b[39mfor\u001b[39;00m it \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(max_num_mbatches):\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:368\u001b[0m, in \u001b[0;36mDataLoader.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=365'>366</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_iterator\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=366'>367</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=367'>368</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_iterator()\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:314\u001b[0m, in \u001b[0;36mDataLoader._get_iterator\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=311'>312</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=312'>313</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcheck_worker_number_rationality()\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=313'>314</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _MultiProcessingDataLoaderIter(\u001b[39mself\u001b[39;49m)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:927\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter.__init__\u001b[1;34m(self, loader)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=919'>920</a>\u001b[0m w\u001b[39m.\u001b[39mdaemon \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=920'>921</a>\u001b[0m \u001b[39m# NB: Process.start() actually take some time as it needs to\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=921'>922</a>\u001b[0m \u001b[39m#     start a process and pass the arguments over via a pipe.\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=922'>923</a>\u001b[0m \u001b[39m#     Therefore, we only add a worker to self._workers list after\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=923'>924</a>\u001b[0m \u001b[39m#     it started, so that we do not call .join() if program dies\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=924'>925</a>\u001b[0m \u001b[39m#     before it starts, and __del__ tries to join but will get:\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=925'>926</a>\u001b[0m \u001b[39m#     AssertionError: can only join a started process.\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=926'>927</a>\u001b[0m w\u001b[39m.\u001b[39;49mstart()\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=927'>928</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues\u001b[39m.\u001b[39mappend(index_queue)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/utils/data/dataloader.py?line=928'>929</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers\u001b[39m.\u001b[39mappend(w)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\multiprocessing\\process.py:121\u001b[0m, in \u001b[0;36mBaseProcess.start\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/process.py?line=117'>118</a>\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m _current_process\u001b[39m.\u001b[39m_config\u001b[39m.\u001b[39mget(\u001b[39m'\u001b[39m\u001b[39mdaemon\u001b[39m\u001b[39m'\u001b[39m), \\\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/process.py?line=118'>119</a>\u001b[0m        \u001b[39m'\u001b[39m\u001b[39mdaemonic processes are not allowed to have children\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/process.py?line=119'>120</a>\u001b[0m _cleanup()\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/process.py?line=120'>121</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_Popen(\u001b[39mself\u001b[39;49m)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/process.py?line=121'>122</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sentinel \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen\u001b[39m.\u001b[39msentinel\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/process.py?line=122'>123</a>\u001b[0m \u001b[39m# Avoid a refcycle if the target function holds an indirect\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/process.py?line=123'>124</a>\u001b[0m \u001b[39m# reference to the process object (see bpo-30775)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\multiprocessing\\context.py:224\u001b[0m, in \u001b[0;36mProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/context.py?line=221'>222</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/context.py?line=222'>223</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/context.py?line=223'>224</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m _default_context\u001b[39m.\u001b[39;49mget_context()\u001b[39m.\u001b[39;49mProcess\u001b[39m.\u001b[39;49m_Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\multiprocessing\\context.py:327\u001b[0m, in \u001b[0;36mSpawnProcess._Popen\u001b[1;34m(process_obj)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/context.py?line=323'>324</a>\u001b[0m \u001b[39m@staticmethod\u001b[39m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/context.py?line=324'>325</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_Popen\u001b[39m(process_obj):\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/context.py?line=325'>326</a>\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mpopen_spawn_win32\u001b[39;00m \u001b[39mimport\u001b[39;00m Popen\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/context.py?line=326'>327</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m Popen(process_obj)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\multiprocessing\\popen_spawn_win32.py:93\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, process_obj)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/popen_spawn_win32.py?line=90'>91</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/popen_spawn_win32.py?line=91'>92</a>\u001b[0m     reduction\u001b[39m.\u001b[39mdump(prep_data, to_child)\n\u001b[1;32m---> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/popen_spawn_win32.py?line=92'>93</a>\u001b[0m     reduction\u001b[39m.\u001b[39;49mdump(process_obj, to_child)\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/popen_spawn_win32.py?line=93'>94</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/popen_spawn_win32.py?line=94'>95</a>\u001b[0m     set_spawning_popen(\u001b[39mNone\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\multiprocessing\\reduction.py:60\u001b[0m, in \u001b[0;36mdump\u001b[1;34m(obj, file, protocol)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/reduction.py?line=57'>58</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdump\u001b[39m(obj, file, protocol\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/reduction.py?line=58'>59</a>\u001b[0m     \u001b[39m'''Replacement for pickle.dump() using ForkingPickler.'''\u001b[39;00m\n\u001b[1;32m---> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/multiprocessing/reduction.py?line=59'>60</a>\u001b[0m     ForkingPickler(file, protocol)\u001b[39m.\u001b[39;49mdump(obj)\n",
      "\u001b[1;31mPicklingError\u001b[0m: Can't pickle <function <lambda> at 0x000001B8AF9EAC10>: attribute lookup <lambda> on __main__ failed"
     ]
    }
   ],
   "source": [
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    strategies.train(exp, num_workers=4)\n",
    "    strategies.eval(eval_exps, num_workers=4)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
