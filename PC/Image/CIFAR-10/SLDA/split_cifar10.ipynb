{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.datasets import CIFAR10\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.models import SLDAResNetModel\n",
    "from avalanche.training import StreamingLDA\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train_set = CIFAR10('../data', train=True, download=True)\n",
    "test_set = CIFAR10('../data', train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_set = AvalancheDataset(train_set, transform=train_transform)\n",
    "test_set = AvalancheDataset(test_set, transform=eval_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3w23ku6s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14024... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">SLDA-CIFAR10</strong>: <a href=\"https://wandb.ai/hopo55/Avalanche/runs/3w23ku6s\" target=\"_blank\">https://wandb.ai/hopo55/Avalanche/runs/3w23ku6s</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220606_081340-3w23ku6s\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3w23ku6s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: wandb version 0.12.17 is available!  To upgrade, please run:\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m:  $ pip install wandb --upgrade\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hopo55/Avalanche/runs/18dti9k2\" target=\"_blank\">SLDA-CIFAR10</a></strong> to <a href=\"https://wandb.ai/hopo55/Avalanche\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(run_name=\"SLDA-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_class = 10\n",
    "incremental = 5\n",
    "fixed_class_order = [4, 1, 7, 5, 3, 9, 0, 8, 6, 2]\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=True,\n",
    "                        seed=seed,\n",
    "                        shuffle=False,\n",
    "                        fixed_class_order=fixed_class_order,\n",
    "                        )\n",
    "\n",
    "model = SLDAResNetModel(imagenet_pretrained=False, device=device)\n",
    "\n",
    "# Prepare for training & testing\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pllugins :  [<avalanche.training.plugins.evaluation.EvaluationPlugin object at 0x0000022C572BC2B0>]\n",
      " 73%|███████▎  | 58/79 [04:16<01:33,  4.43s/it]\n"
     ]
    }
   ],
   "source": [
    "epoch = 70\n",
    "train_batch = 128\n",
    "eval_batch = 64\n",
    "\n",
    "strategies = StreamingLDA(model, criterion, input_size=512, num_classes=num_class, train_epochs=epoch, train_mb_size=train_batch, eval_mb_size=eval_batch, device=device, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 0 (Task 0) from train stream --\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.54it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8212\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.65it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8607\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.61it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8608\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.63it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8615\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.22it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8667\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.39it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8645\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.44it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8622\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.57it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8626\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.41it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8646\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.28it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task000 = 0.8666\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 70.64it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 103.5148\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4264\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task000/Exp000 = 49.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task000/Exp000 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4536\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.8515\n",
      "-- >> End of eval phase << --\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 1 (Task 1) from train stream --\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.70it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4335\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.81it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4738\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.52it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4705\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.05it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4819\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.48it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4785\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.69it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4821\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.78it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4898\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.69it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4869\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.50it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4788\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.74it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task001 = 0.4885\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 74.94it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 100.0071\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.1745\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 0.9505\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task000/Exp000 = 50.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task000/Exp000 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4276\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.6770\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 82.47it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task001/Exp001 = 104.2040\n",
      "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 1.0664\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task001/Exp001 = 15.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task001/Exp001 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task001/Exp001 = 0.3881\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.5360\n",
      "-- >> End of eval phase << --\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 2 (Task 2) from train stream --\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.29it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.3549\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.74it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.3926\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.55it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.3984\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.50it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.4052\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.36it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.4089\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.70it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.4086\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.25it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.4120\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.39it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.4181\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.36it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.4154\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.48it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task002 = 0.4171\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 78.24it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 100.0975\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.2830\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.2884\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task000/Exp000 = 52.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task000/Exp000 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4102\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.5685\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 81.22it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task001/Exp001 = 104.2038\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task001/Exp001 = 0.0925\n",
      "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 1.3818\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task001/Exp001 = 17.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task001/Exp001 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task001/Exp001 = 0.3940\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4435\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 82.26it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task002/Exp002 = 119.9174\n",
      "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 1.4624\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task002/Exp002 = 16.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task002/Exp002 = 4565.5430\n",
      "\tTime_Exp/eval_phase/test_stream/Task002/Exp002 = 0.3896\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.3890\n",
      "-- >> End of eval phase << --\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 3 (Task 3) from train stream --\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.47it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4183\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.13it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4473\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.01it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4524\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.88it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4638\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.95it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4609\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.82it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4660\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.75it/s]\n",
      "Epoch 6 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4683\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.07it/s]\n",
      "Epoch 7 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4733\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.27it/s]\n",
      "Epoch 8 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4832\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.98it/s]\n",
      "Epoch 9 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task003 = 0.4789\n",
      "-- >> End of training phase << --\n",
      "-- >> Start of eval phase << --\n",
      "-- Starting eval on experience 0 (Task 0) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 68.45it/s]\n",
      "> Eval on experience 0 (Task 0) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task000/Exp000 = 103.3104\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task000/Exp000 = 0.3940\n",
      "\tLoss_Exp/eval_phase/test_stream/Task000/Exp000 = 1.6626\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task000/Exp000 = 54.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task000/Exp000 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4683\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task000/Exp000 = 0.4575\n",
      "-- Starting eval on experience 1 (Task 1) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 72.40it/s]\n",
      "> Eval on experience 1 (Task 1) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task001/Exp001 = 103.5082\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task001/Exp001 = 0.1240\n",
      "\tLoss_Exp/eval_phase/test_stream/Task001/Exp001 = 1.5796\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task001/Exp001 = 18.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task001/Exp001 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4426\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task001/Exp001 = 0.4120\n",
      "-- Starting eval on experience 2 (Task 2) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 72.73it/s]\n",
      "> Eval on experience 2 (Task 2) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task002/Exp002 = 103.4849\n",
      "\tExperienceForgetting/eval_phase/test_stream/Task002/Exp002 = 0.0785\n",
      "\tLoss_Exp/eval_phase/test_stream/Task002/Exp002 = 1.7709\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task002/Exp002 = 20.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task002/Exp002 = 4565.5508\n",
      "\tTime_Exp/eval_phase/test_stream/Task002/Exp002 = 0.4403\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task002/Exp002 = 0.3105\n",
      "-- Starting eval on experience 3 (Task 3) from test stream --\n",
      "100%|██████████| 32/32 [00:00<00:00, 71.65it/s]\n",
      "> Eval on experience 3 (Task 3) from test stream ended.\n",
      "\tCPUUsage_Exp/eval_phase/test_stream/Task003/Exp003 = 103.4849\n",
      "\tLoss_Exp/eval_phase/test_stream/Task003/Exp003 = 1.2590\n",
      "\tMaxGPU0Usage_Experience/eval_phase/test_stream/Task003/Exp003 = 16.0000\n",
      "\tMaxRAMUsage_Experience/eval_phase/test_stream/Task003/Exp003 = 0\n",
      "\tTime_Exp/eval_phase/test_stream/Task003/Exp003 = 0.4469\n",
      "\tTop1_Acc_Exp/eval_phase/test_stream/Task003/Exp003 = 0.5660\n",
      "-- >> End of eval phase << --\n",
      "-- >> Start of training phase << --\n",
      "-- Starting training on experience 4 (Task 4) from train stream --\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.62it/s]\n",
      "Epoch 0 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.3153\n",
      "100%|██████████| 79/79 [00:05<00:00, 13.90it/s]\n",
      "Epoch 1 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.3411\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.00it/s]\n",
      "Epoch 2 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.3466\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.28it/s]\n",
      "Epoch 3 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.3482\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.00it/s]\n",
      "Epoch 4 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.3498\n",
      "100%|██████████| 79/79 [00:05<00:00, 14.21it/s]\n",
      "Epoch 5 ended.\n",
      "\tTop1_Acc_Epoch/train_phase/train_stream/Task004 = 0.3516\n",
      " 51%|█████     | 40/79 [00:02<00:02, 14.12it/s]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\LAB\\Desktop\\Archive\\PC\\Image\\CIFAR-10\\SLDA\\split_cifar10.ipynb Cell 7'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/SLDA/split_cifar10.ipynb#ch0000006?line=0'>1</a>\u001b[0m \u001b[39mfor\u001b[39;00m i, exp \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(scenario\u001b[39m.\u001b[39mtrain_stream):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/SLDA/split_cifar10.ipynb#ch0000006?line=1'>2</a>\u001b[0m     eval_exps \u001b[39m=\u001b[39m [e \u001b[39mfor\u001b[39;00m e \u001b[39min\u001b[39;00m scenario\u001b[39m.\u001b[39mtest_stream][: i \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m]\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/SLDA/split_cifar10.ipynb#ch0000006?line=2'>3</a>\u001b[0m     strategies\u001b[39m.\u001b[39;49mtrain(exp)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/LAB/Desktop/Archive/PC/Image/CIFAR-10/SLDA/split_cifar10.ipynb#ch0000006?line=3'>4</a>\u001b[0m     strategies\u001b[39m.\u001b[39meval(eval_exps)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\base_strategy.py:281\u001b[0m, in \u001b[0;36mBaseStrategy.train\u001b[1;34m(self, experiences, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=277'>278</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_periodic_eval(eval_streams, do_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, do_initial\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=279'>280</a>\u001b[0m \u001b[39mfor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperience \u001b[39min\u001b[39;00m experiences:\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=280'>281</a>\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_exp(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mexperience, eval_streams, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=282'>283</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=284'>285</a>\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mevaluator\u001b[39m.\u001b[39mget_last_metrics()\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\base_strategy.py:331\u001b[0m, in \u001b[0;36mBaseStrategy.train_exp\u001b[1;34m(self, experience, eval_streams, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=327'>328</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stop_training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=328'>329</a>\u001b[0m     \u001b[39mbreak\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=330'>331</a>\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtraining_epoch(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=331'>332</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_training_epoch(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/base_strategy.py?line=332'>333</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_periodic_eval(eval_streams, do_final\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\deep_slda.py:112\u001b[0m, in \u001b[0;36mStreamingLDA.training_epoch\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=109'>110</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_before_forward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=110'>111</a>\u001b[0m \u001b[39m# compute output on entire minibatch\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=111'>112</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmb_output, feats \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward(return_features\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=112'>113</a>\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_after_forward(\u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=114'>115</a>\u001b[0m \u001b[39m# Loss & Backward\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\deep_slda.py:91\u001b[0m, in \u001b[0;36mStreamingLDA.forward\u001b[1;34m(self, return_features)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=88'>89</a>\u001b[0m \u001b[39melse\u001b[39;00m:  \u001b[39m# no task labels\u001b[39;00m\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=89'>90</a>\u001b[0m     feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmb_x)\n\u001b[1;32m---> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=90'>91</a>\u001b[0m out \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpredict(feat)\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=91'>92</a>\u001b[0m \u001b[39mif\u001b[39;00m return_features:\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=92'>93</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m out, feat\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\torch\\autograd\\grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/autograd/grad_mode.py?line=23'>24</a>\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/autograd/grad_mode.py?line=24'>25</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[0;32m     <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/autograd/grad_mode.py?line=25'>26</a>\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[1;32m---> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/torch/autograd/grad_mode.py?line=26'>27</a>\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\avalanche\\training\\strategies\\deep_slda.py:167\u001b[0m, in \u001b[0;36mStreamingLDA.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=163'>164</a>\u001b[0m \u001b[39m# compute/load Lambda matrix\u001b[39;00m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=164'>165</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_num_updates \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_updates:\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=165'>166</a>\u001b[0m     \u001b[39m# there have been updates to the model, compute Lambda\u001b[39;00m\n\u001b[1;32m--> <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=166'>167</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLambda \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mpinverse(\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=167'>168</a>\u001b[0m         (\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=168'>169</a>\u001b[0m                 \u001b[39m1\u001b[39;49m \u001b[39m-\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinkage_param) \u001b[39m*\u001b[39;49m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mSigma \u001b[39m+\u001b[39;49m\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=169'>170</a>\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mshrinkage_param \u001b[39m*\u001b[39;49m torch\u001b[39m.\u001b[39;49meye(\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=170'>171</a>\u001b[0m             \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49minput_size, device\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdevice))\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=171'>172</a>\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprev_num_updates \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_updates\n\u001b[0;32m    <a href='file:///c%3A/Users/LAB/Anaconda3/envs/lab/lib/site-packages/avalanche/training/strategies/deep_slda.py?line=173'>174</a>\u001b[0m \u001b[39m# parameters for predictions\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
