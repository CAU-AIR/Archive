{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ec8ed9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.models import SLDAResNetModel\n",
    "from avalanche.training import StreamingLDA\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bd0aa630",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "71d553ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitcifar = SplitCIFAR10(n_experiences=5, seed=seed, dataset_root='../data')\n",
    "\n",
    "train_set = splitcifar.train_stream\n",
    "test_set = splitcifar.test_stream\n",
    "\n",
    "print(splitcifar.classes_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2496ade1",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(run_name=\"SLDA-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f93dbe54",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "model = SLDAResNetModel(imagenet_pretrained=False, device=device)\n",
    "\n",
    "# Prepare for training & testing\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fb00adfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "train_batch = 128\n",
    "eval_batch = 64\n",
    "\n",
    "strategies = StreamingLDA(model, criterion, input_size=32, num_classes=num_class, train_epochs=epoch, train_mb_size=train_batch, eval_mb_size=eval_batch, device=device, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa4c7ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(train_set):\n",
    "    eval_exps = test_set[i]\n",
    "    # eval_exps = [e for e in test_set][i]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4410334b",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "train_batch = 128\n",
    "eval_batch = 64\n",
    "\n",
    "strategies = StreamingLDA(model, criterion, input_size=512, num_classes=num_class, train_epochs=epoch, train_mb_size=train_batch, eval_mb_size=eval_batch, device=device, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "98f5e75d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(train_set):\n",
    "    eval_exps = test_set[i]\n",
    "    # eval_exps = [e for e in test_set][i]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6c06b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f8e86555",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.models import SLDAResNetModel\n",
    "from avalanche.training import StreamingLDA\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1790eeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c624d771",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitcifar = SplitCIFAR10(n_experiences=5, seed=seed, dataset_root='../data')\n",
    "\n",
    "train_set = splitcifar.train_stream\n",
    "test_set = splitcifar.test_stream\n",
    "\n",
    "print(splitcifar.classes_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e6b4c1b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(run_name=\"SLDA-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "627eb533",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_class = 10\n",
    "incremental = 5\n",
    "fixed_class_order = [4, 1, 7, 5, 3, 9, 0, 8, 6, 2]\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=True,\n",
    "                        seed=seed,\n",
    "                        shuffle=False,\n",
    "                        fixed_class_order=fixed_class_order,\n",
    "                        )\n",
    "\n",
    "model = SLDAResNetModel(imagenet_pretrained=False, device=device)\n",
    "\n",
    "# Prepare for training & testing\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96b72bfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.datasets import CIFAR10\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.models import SLDAResNetModel\n",
    "from avalanche.training import StreamingLDA\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3ba9e91a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "73e4f217",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CIFAR10('../data', train=True, download=True)\n",
    "test_set = CIFAR10('../data', train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_set = AvalancheDataset(train_set, transform=train_transform)\n",
    "test_set = AvalancheDataset(test_set, transform=eval_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e0e6689f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Finishing last run (ID:3w23ku6s) before initializing another..."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br/>Waiting for W&B process to finish, PID 14024... <strong style=\"color:green\">(success).</strong>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<style>\n",
       "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
       "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
       "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
       "</div><div class=\"wandb-col\">\n",
       "</div></div>\n",
       "Synced 6 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)\n",
       "<br/>Synced <strong style=\"color:#cdcd00\">SLDA-CIFAR10</strong>: <a href=\"https://wandb.ai/hopo55/Avalanche/runs/3w23ku6s\" target=\"_blank\">https://wandb.ai/hopo55/Avalanche/runs/3w23ku6s</a><br/>\n",
       "Find logs at: <code>.\\wandb\\run-20220606_081340-3w23ku6s\\logs</code><br/>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Successfully finished last run (ID:3w23ku6s). Initializing new run:<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hopo55/Avalanche/runs/18dti9k2\" target=\"_blank\">SLDA-CIFAR10</a></strong> to <a href=\"https://wandb.ai/hopo55/Avalanche\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(run_name=\"SLDA-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "779f622f",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_class = 10\n",
    "incremental = 5\n",
    "fixed_class_order = [4, 1, 7, 5, 3, 9, 0, 8, 6, 2]\n",
    "\n",
    "scenario = nc_benchmark(train_dataset=train_set,\n",
    "                        test_dataset=test_set,\n",
    "                        n_experiences=incremental,\n",
    "                        task_labels=True,\n",
    "                        seed=seed,\n",
    "                        shuffle=False,\n",
    "                        fixed_class_order=fixed_class_order,\n",
    "                        )\n",
    "\n",
    "model = SLDAResNetModel(imagenet_pretrained=False, device=device)\n",
    "\n",
    "# Prepare for training & testing\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "687a5842",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "train_batch = 128\n",
    "eval_batch = 64\n",
    "\n",
    "strategies = StreamingLDA(model, criterion, input_size=512, num_classes=num_class, train_epochs=epoch, train_mb_size=train_batch, eval_mb_size=eval_batch, device=device, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "354ba5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec7ad3b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.benchmarks.datasets import CIFAR10\n",
    "from avalanche.benchmarks.utils import AvalancheDataset\n",
    "from avalanche.models import SLDAResNetModel\n",
    "from avalanche.training import StreamingLDA\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "00b54712",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a7801613",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = CIFAR10('../data', train=True, download=True)\n",
    "test_set = CIFAR10('../data', train=False, download=True)\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "eval_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465),\n",
    "                         (0.2023, 0.1994, 0.2010))\n",
    "])\n",
    "\n",
    "train_set = AvalancheDataset(train_set, transform=train_transform)\n",
    "test_set = AvalancheDataset(test_set, transform=eval_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "ffe78d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(run_name=\"SLDA-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
