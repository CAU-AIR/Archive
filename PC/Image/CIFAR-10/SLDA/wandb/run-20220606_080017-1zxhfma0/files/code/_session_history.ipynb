{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "20aad663",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.models import SLDAResNetModel\n",
    "from avalanche.training import StreamingLDA\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "724c3500",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "40ca3087",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitcifar = SplitCIFAR10(n_experiences=5, seed=seed, dataset_root='../data')\n",
    "\n",
    "train_set = splitcifar.train_stream\n",
    "test_set = splitcifar.test_stream\n",
    "\n",
    "print(splitcifar.classes_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "095759c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "                    Syncing run <strong><a href=\"https://wandb.ai/hopo55/Avalanche/runs/1zxhfma0\" target=\"_blank\">SLDA-CIFAR10</a></strong> to <a href=\"https://wandb.ai/hopo55/Avalanche\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
       "\n",
       "                "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(run_name=\"SLDA-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc13143",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "model = SLDAResNetModel(imagenet_pretrained=False, device=device)\n",
    "\n",
    "# Prepare for training & testing\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9, weight_decay=1e-4)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "816e21c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "train_batch = 128\n",
    "eval_batch = 64\n",
    "\n",
    "strategies = StreamingLDA(model, criterion, input_size=32, num_classes=num_class, train_epochs=epoch, train_mb_size=train_batch, eval_mb_size=eval_batch, device=device, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b4de98a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(train_set):\n",
    "    eval_exps = test_set[i]\n",
    "    # eval_exps = [e for e in test_set][i]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "69e94e33",
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "train_batch = 128\n",
    "eval_batch = 64\n",
    "\n",
    "strategies = StreamingLDA(model, criterion, input_size=512, num_classes=num_class, train_epochs=epoch, train_mb_size=train_batch, eval_mb_size=eval_batch, device=device, evaluator=eval_plugin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "69f2ac58",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(train_set):\n",
    "    eval_exps = test_set[i]\n",
    "    # eval_exps = [e for e in test_set][i]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "39c5cae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, exp in enumerate(scenario.train_stream):\n",
    "    eval_exps = [e for e in scenario.test_stream][: i + 1]\n",
    "    strategies.train(exp)\n",
    "    strategies.eval(eval_exps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d35fe4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from torchvision import transforms\n",
    "\n",
    "from avalanche.benchmarks.classic import SplitCIFAR10\n",
    "from avalanche.models import SLDAResNetModel\n",
    "from avalanche.training import StreamingLDA\n",
    "from avalanche.logging import InteractiveLogger\n",
    "from avalanche.logging import InteractiveLogger, WandBLogger\n",
    "from avalanche.benchmarks.generators import nc_benchmark\n",
    "from avalanche.training.plugins import EvaluationPlugin\n",
    "from avalanche.evaluation.metrics import ExperienceAccuracy, ExperienceLoss, ExperienceForgetting, ExperienceCPUUsage, ExperienceMaxGPU, ExperienceMaxRAM, ExperienceTime, EpochAccuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7c71bce",
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "361f269e",
   "metadata": {},
   "outputs": [],
   "source": [
    "splitcifar = SplitCIFAR10(n_experiences=5, seed=seed, dataset_root='../data')\n",
    "\n",
    "train_set = splitcifar.train_stream\n",
    "test_set = splitcifar.test_stream\n",
    "\n",
    "print(splitcifar.classes_order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "95051e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "interactive_logger = InteractiveLogger()\n",
    "wandb_logger = WandBLogger(run_name=\"SLDA-CIFAR10\")\n",
    "eval_plugin = EvaluationPlugin(\n",
    "    EpochAccuracy(),\n",
    "    ExperienceAccuracy(),\n",
    "    ExperienceLoss(),\n",
    "    ExperienceForgetting(),\n",
    "    ExperienceCPUUsage(),\n",
    "    ExperienceMaxGPU(gpu_id=0),\n",
    "    ExperienceMaxRAM(),\n",
    "    ExperienceTime(),\n",
    "    loggers=[interactive_logger, wandb_logger])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
