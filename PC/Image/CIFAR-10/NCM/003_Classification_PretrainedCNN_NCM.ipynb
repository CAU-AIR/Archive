{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN and NCM for CIFAR-10 feature extraction and classification\n",
    "\n",
    "### Summary\n",
    "CIFAR-10 데이터셋을 분류하기 위해 CNN을 이용하여 데이터셋에 대한 특징을 추출 후 NCM을 이용하여 각 class에 대한 평균 값을 이용하여 분류\n",
    "\n",
    "<span style=\"color: #2D3748; background-color:#fff5b1;\">Test size를 0.2로 10번 반복 실험한 결과 평균적으로 0.34의 정확도를 보여주고 있고, test 데이터 1개를 분류하는데 0.0011초의 시간이 걸린다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils.util import Info\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from utils.Data_Classifier import train, validate, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(Info):\n",
    "    def __init__(self):\n",
    "        super(Info, self).__init__()\n",
    "        self.device = 'PC'\n",
    "        self.dataset = 'CIFAR_10'\n",
    "        self.test_size = 0.2\n",
    "        self.feature_size = 3072\n",
    "        self.method = 'CNN'\n",
    "        self.iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cig = Config()\n",
    "# cig.info()\n",
    "# cig.print_rutin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                      ])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize(224),\n",
    "                                     transforms.ToTensor(),                                     \n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                     ])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "validationset = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "val_loader = DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "print(validationset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch = 10\n",
    "num_class = 10\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_feature = model.fc.in_features\n",
    "model.fc = nn.Linear(num_feature, num_class)\n",
    "model.to(device)\n",
    "\n",
    "feature_extract = True\n",
    "\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]\n",
      "Train: [98/98]\tTime 0.3971\tData 0.0558\tLoss 1.9159\tAcc 67.76\n",
      "Test: [20/20]\tTime 0.4406\tData 0.1264\tLoss 0.8629\tAcc 77.31\n",
      "Epoch: [1]\n",
      "Train: [98/98]\tTime 0.4356\tData 0.0571\tLoss 0.7673\tAcc 77.53\n",
      "Test: [20/20]\tTime 0.4820\tData 0.1441\tLoss 0.7883\tAcc 76.18\n",
      "Epoch: [2]\n",
      "Train: [98/98]\tTime 0.4100\tData 0.0553\tLoss 0.6762\tAcc 78.38\n",
      "Test: [20/20]\tTime 0.4669\tData 0.1295\tLoss 0.7598\tAcc 76.33\n",
      "Epoch: [3]\n",
      "Train: [98/98]\tTime 0.4730\tData 0.0793\tLoss 0.6269\tAcc 79.16\n",
      "Test: [20/20]\tTime 0.4955\tData 0.1477\tLoss 0.7059\tAcc 76.88\n",
      "Epoch: [4]\n",
      "Train: [98/98]\tTime 0.4806\tData 0.0820\tLoss 0.6351\tAcc 79.00\n",
      "Test: [20/20]\tTime 0.6326\tData 0.1505\tLoss 0.7608\tAcc 76.48\n",
      "Epoch: [5]\n",
      "Train: [98/98]\tTime 0.4806\tData 0.0975\tLoss 0.6394\tAcc 79.17\n",
      "Test: [20/20]\tTime 0.4944\tData 0.1518\tLoss 0.6506\tAcc 78.98\n",
      "Epoch: [6]\n",
      "Train: [98/98]\tTime 0.4781\tData 0.0836\tLoss 0.6824\tAcc 78.25\n",
      "Test: [20/20]\tTime 0.4274\tData 0.1401\tLoss 0.9444\tAcc 73.43\n",
      "Epoch: [7]\n",
      "Train: [98/98]\tTime 0.3801\tData 0.0533\tLoss 0.6610\tAcc 78.93\n",
      "Test: [20/20]\tTime 0.5099\tData 0.1286\tLoss 0.7062\tAcc 77.67\n",
      "Epoch: [8]\n",
      "Train: [98/98]\tTime 0.4695\tData 0.1061\tLoss 0.6387\tAcc 79.11\n",
      "Test: [20/20]\tTime 0.5111\tData 0.1509\tLoss 0.6074\tAcc 80.27\n",
      "Epoch: [9]\n",
      "Train: [98/98]\tTime 0.4885\tData 0.1046\tLoss 0.6568\tAcc 78.97\n",
      "Test: [20/20]\tTime 0.6023\tData 0.1620\tLoss 0.6931\tAcc 77.80\n",
      "\n",
      "Finished Training\n",
      "\n",
      "Total Average Training Time : 44.20 ± 3.76 sec\n",
      "Total Average Validation Time : 10.27 ± 1.25 sec\n",
      "\n",
      "Total Best Validation Accuracy : 80.27 %\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "train_time = []\n",
    "val_time = []\n",
    "\n",
    "for idx in range(epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    # train for one epoch\n",
    "    end = time.time()\n",
    "    train(train_loader, model, criterion, optimizer, idx, device)\n",
    "    train_time.append(time.time() - end)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    end = time.time()\n",
    "    acc = validate(val_loader, model, criterion, device)\n",
    "    val_time.append(time.time() - end)\n",
    "\n",
    "    # remember best acc and save checkpoint\n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "\n",
    "    save_checkpoint({\n",
    "            'epoch': idx + 1,\n",
    "            'arch': \"ResNet-18\",\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "train_time = np.array(train_time)\n",
    "val_time = np.array(val_time)\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Average Training Time : %.2f ± %.2f\" % (train_time.mean(), train_time.std()), \"sec\")\n",
    "print(\"Total Average Validation Time : %.2f ± %.2f\" % (val_time.mean(), val_time.std()), \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % best_acc.real, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning NCM instead of Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NCM_Classifier import train, validate, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Training\n",
      "\n",
      "Total Training Time : 36.65 sec\n",
      "Total Validation Time : 9.56 sec\n",
      "\n",
      "Total Best Validation Accuracy : 76.98 %\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "\n",
    "# train for one epoch\n",
    "end = time.time()\n",
    "x_train, y_train = train(train_loader, model, device)\n",
    "\n",
    "nc = NearestCentroid()\n",
    "nc.fit(x_train, y_train)\n",
    "train_time = time.time() - end\n",
    "\n",
    "# evaluate on validation set\n",
    "end = time.time()\n",
    "x_test, y_test = validate(val_loader, model, device)\n",
    "\n",
    "test_score = nc.score(x_test, y_test)\n",
    "val_time = time.time() - end\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Training Time : %.2f\" % train_time, \"sec\")\n",
    "print(\"Total Validation Time : %.2f\" % val_time, \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % (test_score*100), \"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
