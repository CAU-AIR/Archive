{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN and NCM for CIFAR-10 feature extraction and classification\n",
    "\n",
    "### Summary\n",
    "CIFAR-10 데이터셋을 분류하기 위해 CNN을 이용하여 데이터셋에 대한 특징을 추출 후 NCM을 이용하여 각 class에 대한 평균 값을 이용하여 분류\n",
    "\n",
    "<span style=\"color: #2D3748; background-color:#fff5b1;\">Test size를 0.2로 10번 반복 실험한 결과 평균적으로 0.34의 정확도를 보여주고 있고, test 데이터 1개를 분류하는데 0.0011초의 시간이 걸린다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from utils.Data_Classifier import train, validate, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                ])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "validationset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "val_loader = DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "print(validationset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch = 100\n",
    "num_class = 10\n",
    "\n",
    "model = resnet18(num_classes=num_class)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0225\tLoss 2.1219\tAcc 33.14\n",
      "Test: [20/20]\tTime 0.0944\tData 0.0852\tLoss 16.4620\tAcc 39.76\n",
      "Epoch: [1]\n",
      "Train: [98/98]\tTime 0.0491\tData 0.0227\tLoss 1.5159\tAcc 47.11\n",
      "Test: [20/20]\tTime 0.0937\tData 0.0826\tLoss 1.3771\tAcc 51.05\n",
      "Epoch: [2]\n",
      "Train: [98/98]\tTime 0.0501\tData 0.0232\tLoss 1.3283\tAcc 53.97\n",
      "Test: [20/20]\tTime 0.0961\tData 0.0838\tLoss 1.2378\tAcc 55.38\n",
      "Epoch: [3]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0226\tLoss 1.1447\tAcc 60.39\n",
      "Test: [20/20]\tTime 0.0902\tData 0.0801\tLoss 1.1518\tAcc 59.36\n",
      "Epoch: [4]\n",
      "Train: [98/98]\tTime 0.0488\tData 0.0227\tLoss 1.0506\tAcc 64.86\n",
      "Test: [20/20]\tTime 0.0920\tData 0.0817\tLoss 11.4038\tAcc 48.03\n",
      "Epoch: [5]\n",
      "Train: [98/98]\tTime 0.0501\tData 0.0233\tLoss 0.9206\tAcc 69.23\n",
      "Test: [20/20]\tTime 0.0973\tData 0.0846\tLoss 1.0033\tAcc 66.22\n",
      "Epoch: [6]\n",
      "Train: [98/98]\tTime 0.0502\tData 0.0233\tLoss 0.7450\tAcc 74.36\n",
      "Test: [20/20]\tTime 0.0933\tData 0.0801\tLoss 0.9484\tAcc 68.70\n",
      "Epoch: [7]\n",
      "Train: [98/98]\tTime 0.0501\tData 0.0232\tLoss 0.6725\tAcc 76.86\n",
      "Test: [20/20]\tTime 0.0960\tData 0.0821\tLoss 0.9261\tAcc 68.66\n",
      "Epoch: [8]\n",
      "Train: [98/98]\tTime 0.0464\tData 0.0219\tLoss 0.5844\tAcc 79.56\n",
      "Test: [20/20]\tTime 0.0902\tData 0.0808\tLoss 0.8827\tAcc 70.68\n",
      "Epoch: [9]\n",
      "Train: [98/98]\tTime 0.0471\tData 0.0221\tLoss 0.4593\tAcc 84.14\n",
      "Test: [20/20]\tTime 0.0914\tData 0.0822\tLoss 0.9209\tAcc 70.51\n",
      "Epoch: [10]\n",
      "Train: [98/98]\tTime 0.0470\tData 0.0219\tLoss 0.4105\tAcc 85.72\n",
      "Test: [20/20]\tTime 0.0944\tData 0.0846\tLoss 0.9855\tAcc 71.07\n",
      "Epoch: [11]\n",
      "Train: [98/98]\tTime 0.0475\tData 0.0222\tLoss 0.3176\tAcc 88.78\n",
      "Test: [20/20]\tTime 0.0922\tData 0.0831\tLoss 1.0382\tAcc 70.37\n",
      "Epoch: [12]\n",
      "Train: [98/98]\tTime 0.0465\tData 0.0215\tLoss 0.2628\tAcc 90.74\n",
      "Test: [20/20]\tTime 0.0933\tData 0.0840\tLoss 1.1093\tAcc 70.18\n",
      "Epoch: [13]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0224\tLoss 0.2041\tAcc 92.81\n",
      "Test: [20/20]\tTime 0.0918\tData 0.0824\tLoss 1.1906\tAcc 70.82\n",
      "Epoch: [14]\n",
      "Train: [98/98]\tTime 0.0487\tData 0.0232\tLoss 0.1756\tAcc 93.69\n",
      "Test: [20/20]\tTime 0.0929\tData 0.0835\tLoss 1.1605\tAcc 71.71\n",
      "Epoch: [15]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0230\tLoss 0.1303\tAcc 95.30\n",
      "Test: [20/20]\tTime 0.0911\tData 0.0818\tLoss 1.3825\tAcc 71.60\n",
      "Epoch: [16]\n",
      "Train: [98/98]\tTime 0.0472\tData 0.0222\tLoss 0.1181\tAcc 95.80\n",
      "Test: [20/20]\tTime 0.0939\tData 0.0847\tLoss 1.3753\tAcc 71.32\n",
      "Epoch: [17]\n",
      "Train: [98/98]\tTime 0.0491\tData 0.0229\tLoss 0.1076\tAcc 96.22\n",
      "Test: [20/20]\tTime 0.0931\tData 0.0822\tLoss 1.4223\tAcc 70.75\n",
      "Epoch: [18]\n",
      "Train: [98/98]\tTime 0.0485\tData 0.0226\tLoss 0.0782\tAcc 97.24\n",
      "Test: [20/20]\tTime 0.0914\tData 0.0815\tLoss 1.4714\tAcc 71.55\n",
      "Epoch: [19]\n",
      "Train: [98/98]\tTime 0.0485\tData 0.0222\tLoss 0.0797\tAcc 97.21\n",
      "Test: [20/20]\tTime 0.0897\tData 0.0800\tLoss 1.5083\tAcc 71.46\n",
      "Epoch: [20]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0218\tLoss 0.0736\tAcc 97.44\n",
      "Test: [20/20]\tTime 0.0944\tData 0.0848\tLoss 1.5276\tAcc 71.75\n",
      "Epoch: [21]\n",
      "Train: [98/98]\tTime 0.0487\tData 0.0223\tLoss 0.0602\tAcc 97.89\n",
      "Test: [20/20]\tTime 0.0925\tData 0.0824\tLoss 1.5950\tAcc 71.78\n",
      "Epoch: [22]\n",
      "Train: [98/98]\tTime 0.0489\tData 0.0223\tLoss 0.0482\tAcc 98.35\n",
      "Test: [20/20]\tTime 0.0929\tData 0.0807\tLoss 1.6111\tAcc 71.89\n",
      "Epoch: [23]\n",
      "Train: [98/98]\tTime 0.0494\tData 0.0228\tLoss 0.0440\tAcc 98.40\n",
      "Test: [20/20]\tTime 0.0975\tData 0.0862\tLoss 1.6963\tAcc 72.00\n",
      "Epoch: [24]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0224\tLoss 0.0429\tAcc 98.50\n",
      "Test: [20/20]\tTime 0.0959\tData 0.0815\tLoss 1.5965\tAcc 71.93\n",
      "Epoch: [25]\n",
      "Train: [98/98]\tTime 0.0493\tData 0.0230\tLoss 0.0341\tAcc 98.79\n",
      "Test: [20/20]\tTime 0.0941\tData 0.0832\tLoss 1.7589\tAcc 72.12\n",
      "Epoch: [26]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0221\tLoss 0.0301\tAcc 98.96\n",
      "Test: [20/20]\tTime 0.0914\tData 0.0815\tLoss 1.7444\tAcc 72.81\n",
      "Epoch: [27]\n",
      "Train: [98/98]\tTime 0.0487\tData 0.0223\tLoss 0.0302\tAcc 98.94\n",
      "Test: [20/20]\tTime 0.0920\tData 0.0818\tLoss 1.7274\tAcc 72.57\n",
      "Epoch: [28]\n",
      "Train: [98/98]\tTime 0.0485\tData 0.0224\tLoss 0.0345\tAcc 98.81\n",
      "Test: [20/20]\tTime 0.0982\tData 0.0834\tLoss 1.7802\tAcc 72.57\n",
      "Epoch: [29]\n",
      "Train: [98/98]\tTime 0.0495\tData 0.0230\tLoss 0.0270\tAcc 99.07\n",
      "Test: [20/20]\tTime 0.0917\tData 0.0808\tLoss 1.7934\tAcc 72.70\n",
      "Epoch: [30]\n",
      "Train: [98/98]\tTime 0.0486\tData 0.0219\tLoss 0.0203\tAcc 99.32\n",
      "Test: [20/20]\tTime 0.0935\tData 0.0809\tLoss 1.7668\tAcc 73.20\n",
      "Epoch: [31]\n",
      "Train: [98/98]\tTime 0.0474\tData 0.0226\tLoss 0.0111\tAcc 99.62\n",
      "Test: [20/20]\tTime 0.0922\tData 0.0824\tLoss 1.8926\tAcc 73.13\n",
      "Epoch: [32]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0220\tLoss 0.0131\tAcc 99.57\n",
      "Test: [20/20]\tTime 0.0903\tData 0.0805\tLoss 1.9225\tAcc 73.19\n",
      "Epoch: [33]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0223\tLoss 0.0176\tAcc 99.43\n",
      "Test: [20/20]\tTime 0.0905\tData 0.0802\tLoss 1.9184\tAcc 72.91\n",
      "Epoch: [34]\n",
      "Train: [98/98]\tTime 0.0477\tData 0.0231\tLoss 0.0149\tAcc 99.51\n",
      "Test: [20/20]\tTime 0.0921\tData 0.0823\tLoss 1.9275\tAcc 73.37\n",
      "Epoch: [35]\n",
      "Train: [98/98]\tTime 0.0492\tData 0.0228\tLoss 0.0118\tAcc 99.60\n",
      "Test: [20/20]\tTime 0.0902\tData 0.0807\tLoss 1.8890\tAcc 73.26\n",
      "Epoch: [36]\n",
      "Train: [98/98]\tTime 0.0490\tData 0.0223\tLoss 0.0097\tAcc 99.67\n",
      "Test: [20/20]\tTime 0.0942\tData 0.0834\tLoss 1.9712\tAcc 73.96\n",
      "Epoch: [37]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0222\tLoss 0.0080\tAcc 99.76\n",
      "Test: [20/20]\tTime 0.0988\tData 0.0835\tLoss 2.0127\tAcc 73.52\n",
      "Epoch: [38]\n",
      "Train: [98/98]\tTime 0.0501\tData 0.0228\tLoss 0.0098\tAcc 99.69\n",
      "Test: [20/20]\tTime 0.0934\tData 0.0838\tLoss 1.9803\tAcc 73.86\n",
      "Epoch: [39]\n",
      "Train: [98/98]\tTime 0.0481\tData 0.0224\tLoss 0.0059\tAcc 99.83\n",
      "Test: [20/20]\tTime 0.0914\tData 0.0823\tLoss 2.0136\tAcc 73.84\n",
      "Epoch: [40]\n",
      "Train: [98/98]\tTime 0.0479\tData 0.0217\tLoss 0.0037\tAcc 99.88\n",
      "Test: [20/20]\tTime 0.0942\tData 0.0824\tLoss 2.1202\tAcc 74.02\n",
      "Epoch: [41]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0222\tLoss 0.0055\tAcc 99.80\n",
      "Test: [20/20]\tTime 0.0934\tData 0.0810\tLoss 2.0742\tAcc 73.48\n",
      "Epoch: [42]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0223\tLoss 0.0066\tAcc 99.78\n",
      "Test: [20/20]\tTime 0.0908\tData 0.0810\tLoss 2.1080\tAcc 73.10\n",
      "Epoch: [43]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0228\tLoss 0.0065\tAcc 99.80\n",
      "Test: [20/20]\tTime 0.0928\tData 0.0831\tLoss 1.9640\tAcc 74.13\n",
      "Epoch: [44]\n",
      "Train: [98/98]\tTime 0.0489\tData 0.0228\tLoss 0.0027\tAcc 99.92\n",
      "Test: [20/20]\tTime 0.0932\tData 0.0823\tLoss 2.1109\tAcc 73.85\n",
      "Epoch: [45]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0220\tLoss 0.0026\tAcc 99.93\n",
      "Test: [20/20]\tTime 0.0919\tData 0.0819\tLoss 2.0426\tAcc 74.53\n",
      "Epoch: [46]\n",
      "Train: [98/98]\tTime 0.0490\tData 0.0225\tLoss 0.0010\tAcc 99.98\n",
      "Test: [20/20]\tTime 0.0941\tData 0.0809\tLoss 2.1136\tAcc 74.40\n",
      "Epoch: [47]\n",
      "Train: [98/98]\tTime 0.0485\tData 0.0228\tLoss 0.0005\tAcc 99.99\n",
      "Test: [20/20]\tTime 0.0896\tData 0.0802\tLoss 2.0854\tAcc 74.42\n",
      "Epoch: [48]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0219\tLoss 0.0002\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0912\tData 0.0815\tLoss 2.0752\tAcc 74.73\n",
      "Epoch: [49]\n",
      "Train: [98/98]\tTime 0.0473\tData 0.0217\tLoss 0.0001\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0896\tData 0.0797\tLoss 2.0800\tAcc 74.75\n",
      "Epoch: [50]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0220\tLoss 0.0001\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0891\tData 0.0795\tLoss 2.0656\tAcc 74.69\n",
      "Epoch: [51]\n",
      "Train: [98/98]\tTime 0.0485\tData 0.0221\tLoss 0.0001\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0975\tData 0.0868\tLoss 2.0744\tAcc 74.64\n",
      "Epoch: [52]\n",
      "Train: [98/98]\tTime 0.0501\tData 0.0227\tLoss 0.0001\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0997\tData 0.0851\tLoss 2.0659\tAcc 74.71\n",
      "Epoch: [53]\n",
      "Train: [98/98]\tTime 0.0495\tData 0.0231\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0937\tData 0.0802\tLoss 2.0605\tAcc 74.84\n",
      "Epoch: [54]\n",
      "Train: [98/98]\tTime 0.0481\tData 0.0224\tLoss 0.0001\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0902\tData 0.0804\tLoss 2.0540\tAcc 74.79\n",
      "Epoch: [55]\n",
      "Train: [98/98]\tTime 0.0481\tData 0.0218\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0923\tData 0.0828\tLoss 2.0502\tAcc 74.70\n",
      "Epoch: [56]\n",
      "Train: [98/98]\tTime 0.0490\tData 0.0224\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0889\tData 0.0793\tLoss 2.0420\tAcc 74.80\n",
      "Epoch: [57]\n",
      "Train: [98/98]\tTime 0.0475\tData 0.0219\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0906\tData 0.0811\tLoss 2.0438\tAcc 74.84\n",
      "Epoch: [58]\n",
      "Train: [98/98]\tTime 0.0474\tData 0.0217\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0905\tData 0.0795\tLoss 2.0259\tAcc 74.86\n",
      "Epoch: [59]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0222\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0896\tData 0.0800\tLoss 2.0074\tAcc 74.84\n",
      "Epoch: [60]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0218\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0911\tData 0.0813\tLoss 2.0127\tAcc 74.86\n",
      "Epoch: [61]\n",
      "Train: [98/98]\tTime 0.0478\tData 0.0221\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0923\tData 0.0817\tLoss 2.0153\tAcc 74.90\n",
      "Epoch: [62]\n",
      "Train: [98/98]\tTime 0.0491\tData 0.0227\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0896\tData 0.0798\tLoss 2.0008\tAcc 74.84\n",
      "Epoch: [63]\n",
      "Train: [98/98]\tTime 0.0497\tData 0.0231\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0925\tData 0.0826\tLoss 1.9956\tAcc 74.88\n",
      "Epoch: [64]\n",
      "Train: [98/98]\tTime 0.0487\tData 0.0225\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0908\tData 0.0809\tLoss 2.0006\tAcc 74.86\n",
      "Epoch: [65]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0903\tData 0.0807\tLoss 2.0022\tAcc 74.86\n",
      "Epoch: [66]\n",
      "Train: [98/98]\tTime 0.0479\tData 0.0221\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0914\tData 0.0816\tLoss 1.9808\tAcc 74.89\n",
      "Epoch: [67]\n",
      "Train: [98/98]\tTime 0.0485\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0895\tData 0.0795\tLoss 1.9729\tAcc 74.88\n",
      "Epoch: [68]\n",
      "Train: [98/98]\tTime 0.0486\tData 0.0222\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0904\tData 0.0803\tLoss 1.9689\tAcc 74.89\n",
      "Epoch: [69]\n",
      "Train: [98/98]\tTime 0.0478\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0900\tData 0.0804\tLoss 1.9762\tAcc 74.85\n",
      "Epoch: [70]\n",
      "Train: [98/98]\tTime 0.0480\tData 0.0217\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0881\tData 0.0784\tLoss 1.9625\tAcc 74.80\n",
      "Epoch: [71]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0218\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0906\tData 0.0809\tLoss 1.9584\tAcc 74.86\n",
      "Epoch: [72]\n",
      "Train: [98/98]\tTime 0.0481\tData 0.0218\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0892\tData 0.0794\tLoss 1.9581\tAcc 74.90\n",
      "Epoch: [73]\n",
      "Train: [98/98]\tTime 0.0479\tData 0.0217\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0907\tData 0.0807\tLoss 1.9646\tAcc 74.96\n",
      "Epoch: [74]\n",
      "Train: [98/98]\tTime 0.0472\tData 0.0216\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0905\tData 0.0808\tLoss 1.9575\tAcc 74.88\n",
      "Epoch: [75]\n",
      "Train: [98/98]\tTime 0.0481\tData 0.0218\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0903\tData 0.0807\tLoss 1.9359\tAcc 74.93\n",
      "Epoch: [76]\n",
      "Train: [98/98]\tTime 0.0477\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0894\tData 0.0799\tLoss 1.9409\tAcc 74.86\n",
      "Epoch: [77]\n",
      "Train: [98/98]\tTime 0.0486\tData 0.0223\tLoss 0.0001\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0902\tData 0.0805\tLoss 1.9308\tAcc 74.74\n",
      "Epoch: [78]\n",
      "Train: [98/98]\tTime 0.0474\tData 0.0215\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0902\tData 0.0807\tLoss 1.9518\tAcc 74.96\n",
      "Epoch: [79]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0899\tData 0.0802\tLoss 1.9287\tAcc 74.90\n",
      "Epoch: [80]\n",
      "Train: [98/98]\tTime 0.0478\tData 0.0219\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0909\tData 0.0814\tLoss 1.9417\tAcc 74.87\n",
      "Epoch: [81]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0887\tData 0.0790\tLoss 1.9240\tAcc 75.06\n",
      "Epoch: [82]\n",
      "Train: [98/98]\tTime 0.0478\tData 0.0217\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0910\tData 0.0813\tLoss 1.9406\tAcc 75.02\n",
      "Epoch: [83]\n",
      "Train: [98/98]\tTime 0.0482\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0901\tData 0.0805\tLoss 1.9279\tAcc 74.82\n",
      "Epoch: [84]\n",
      "Train: [98/98]\tTime 0.0475\tData 0.0214\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0885\tData 0.0789\tLoss 1.9415\tAcc 74.98\n",
      "Epoch: [85]\n",
      "Train: [98/98]\tTime 0.0475\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0897\tData 0.0798\tLoss 1.9329\tAcc 74.96\n",
      "Epoch: [86]\n",
      "Train: [98/98]\tTime 0.0480\tData 0.0218\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0895\tData 0.0800\tLoss 1.9284\tAcc 74.82\n",
      "Epoch: [87]\n",
      "Train: [98/98]\tTime 0.0481\tData 0.0219\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0909\tData 0.0812\tLoss 1.9328\tAcc 74.86\n",
      "Epoch: [88]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0906\tData 0.0809\tLoss 1.9304\tAcc 74.90\n",
      "Epoch: [89]\n",
      "Train: [98/98]\tTime 0.0476\tData 0.0221\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0905\tData 0.0804\tLoss 1.9265\tAcc 74.87\n",
      "Epoch: [90]\n",
      "Train: [98/98]\tTime 0.0486\tData 0.0222\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0907\tData 0.0810\tLoss 1.9147\tAcc 74.87\n",
      "Epoch: [91]\n",
      "Train: [98/98]\tTime 0.0472\tData 0.0215\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0890\tData 0.0794\tLoss 1.9269\tAcc 74.85\n",
      "Epoch: [92]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0221\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0900\tData 0.0805\tLoss 1.9268\tAcc 74.93\n",
      "Epoch: [93]\n",
      "Train: [98/98]\tTime 0.0477\tData 0.0218\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0901\tData 0.0804\tLoss 1.9311\tAcc 74.96\n",
      "Epoch: [94]\n",
      "Train: [98/98]\tTime 0.0471\tData 0.0217\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0898\tData 0.0801\tLoss 1.9324\tAcc 74.93\n",
      "Epoch: [95]\n",
      "Train: [98/98]\tTime 0.0484\tData 0.0223\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0884\tData 0.0789\tLoss 1.9358\tAcc 74.98\n",
      "Epoch: [96]\n",
      "Train: [98/98]\tTime 0.0480\tData 0.0221\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0921\tData 0.0820\tLoss 1.9306\tAcc 74.85\n",
      "Epoch: [97]\n",
      "Train: [98/98]\tTime 0.0485\tData 0.0222\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0896\tData 0.0799\tLoss 1.9205\tAcc 74.93\n",
      "Epoch: [98]\n",
      "Train: [98/98]\tTime 0.0483\tData 0.0220\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0895\tData 0.0798\tLoss 1.9208\tAcc 74.77\n",
      "Epoch: [99]\n",
      "Train: [98/98]\tTime 0.0480\tData 0.0217\tLoss 0.0000\tAcc 100.00\n",
      "Test: [20/20]\tTime 0.0910\tData 0.0813\tLoss 1.9128\tAcc 74.93\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "\n",
    "for idx in range(epoch):  # loop over the dataset multiple times\n",
    "    # train for one epoch\n",
    "    train(train_loader, model, criterion, optimizer, idx, device)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    acc = validate(val_loader, model, criterion, device)\n",
    "\n",
    "    # remember best acc@1 and save checkpoint\n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([transforms.RandomCrop(32, padding=4),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                      ])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.ToTensor(),\n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                     ])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "validationset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "val_loader = DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "print(validationset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch = 100\n",
    "num_class = 10\n",
    "\n",
    "model = resnet18(num_classes=num_class)\n",
    "model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]\n",
      "Train: [98/98]\tTime 0.0507\tData 0.0257\tLoss 2.4011\tAcc 26.14\n",
      "Test: [20/20]\tTime 0.0966\tData 0.0867\tLoss 1.6888\tAcc 36.56\n",
      "Epoch: [1]\n",
      "Train: [98/98]\tTime 0.0498\tData 0.0268\tLoss 1.6160\tAcc 40.87\n",
      "Test: [20/20]\tTime 0.1014\tData 0.0895\tLoss 1.4505\tAcc 47.16\n",
      "Epoch: [2]\n",
      "Train: [98/98]\tTime 0.0521\tData 0.0237\tLoss 1.4164\tAcc 48.46\n",
      "Test: [20/20]\tTime 0.1051\tData 0.0901\tLoss 1.4541\tAcc 51.48\n",
      "Epoch: [3]\n",
      "Train: [98/98]\tTime 0.0494\tData 0.0271\tLoss 1.3467\tAcc 51.42\n",
      "Test: [20/20]\tTime 0.0908\tData 0.0812\tLoss 1.2162\tAcc 56.30\n",
      "Epoch: [4]\n",
      "Train: [98/98]\tTime 0.0570\tData 0.0294\tLoss 1.1840\tAcc 57.40\n",
      "Test: [20/20]\tTime 0.1060\tData 0.0886\tLoss 1.1111\tAcc 60.65\n",
      "Epoch: [5]\n",
      "Train: [98/98]\tTime 0.0664\tData 0.0384\tLoss 1.0837\tAcc 61.32\n",
      "Test: [20/20]\tTime 0.1050\tData 0.0890\tLoss 0.9941\tAcc 64.99\n",
      "Epoch: [6]\n",
      "Train: [98/98]\tTime 0.0648\tData 0.0379\tLoss 1.0036\tAcc 64.38\n",
      "Test: [20/20]\tTime 0.1046\tData 0.0877\tLoss 0.9555\tAcc 66.16\n",
      "Epoch: [7]\n",
      "Train: [98/98]\tTime 0.0648\tData 0.0375\tLoss 0.9355\tAcc 67.07\n",
      "Test: [20/20]\tTime 0.1099\tData 0.0900\tLoss 0.9767\tAcc 66.10\n",
      "Epoch: [8]\n",
      "Train: [98/98]\tTime 0.0663\tData 0.0382\tLoss 0.8803\tAcc 68.84\n",
      "Test: [20/20]\tTime 0.1093\tData 0.0892\tLoss 0.9998\tAcc 65.77\n",
      "Epoch: [9]\n",
      "Train: [98/98]\tTime 0.0660\tData 0.0378\tLoss 0.8410\tAcc 70.40\n",
      "Test: [20/20]\tTime 0.1102\tData 0.0908\tLoss 1.0210\tAcc 65.16\n",
      "Epoch: [10]\n",
      "Train: [98/98]\tTime 0.0686\tData 0.0397\tLoss 0.7945\tAcc 72.06\n",
      "Test: [20/20]\tTime 0.1108\tData 0.0921\tLoss 0.8355\tAcc 70.78\n",
      "Epoch: [11]\n",
      "Train: [98/98]\tTime 0.0664\tData 0.0380\tLoss 0.7592\tAcc 73.23\n",
      "Test: [20/20]\tTime 0.1058\tData 0.0888\tLoss 0.7487\tAcc 73.95\n",
      "Epoch: [12]\n",
      "Train: [98/98]\tTime 0.0666\tData 0.0383\tLoss 0.7301\tAcc 74.49\n",
      "Test: [20/20]\tTime 0.1050\tData 0.0889\tLoss 0.7475\tAcc 74.31\n",
      "Epoch: [13]\n",
      "Train: [98/98]\tTime 0.0646\tData 0.0371\tLoss 0.6972\tAcc 75.68\n",
      "Test: [20/20]\tTime 0.1074\tData 0.0887\tLoss 0.8519\tAcc 71.87\n",
      "Epoch: [14]\n",
      "Train: [98/98]\tTime 0.0646\tData 0.0376\tLoss 0.6759\tAcc 76.38\n",
      "Test: [20/20]\tTime 0.1084\tData 0.0892\tLoss 0.7937\tAcc 72.92\n",
      "Epoch: [15]\n",
      "Train: [98/98]\tTime 0.0662\tData 0.0380\tLoss 0.6583\tAcc 77.30\n",
      "Test: [20/20]\tTime 0.1117\tData 0.0908\tLoss 0.7589\tAcc 74.52\n",
      "Epoch: [16]\n",
      "Train: [98/98]\tTime 0.0655\tData 0.0377\tLoss 0.6404\tAcc 77.54\n",
      "Test: [20/20]\tTime 0.1113\tData 0.0907\tLoss 0.7220\tAcc 75.36\n",
      "Epoch: [17]\n",
      "Train: [98/98]\tTime 0.0652\tData 0.0376\tLoss 0.6277\tAcc 78.05\n",
      "Test: [20/20]\tTime 0.1041\tData 0.0885\tLoss 0.7069\tAcc 75.83\n",
      "Epoch: [18]\n",
      "Train: [98/98]\tTime 0.0650\tData 0.0372\tLoss 0.6047\tAcc 78.93\n",
      "Test: [20/20]\tTime 0.1081\tData 0.0891\tLoss 0.6989\tAcc 75.89\n",
      "Epoch: [19]\n",
      "Train: [98/98]\tTime 0.0657\tData 0.0375\tLoss 0.5944\tAcc 79.30\n",
      "Test: [20/20]\tTime 0.1117\tData 0.0910\tLoss 0.6953\tAcc 76.48\n",
      "Epoch: [20]\n",
      "Train: [98/98]\tTime 0.0636\tData 0.0356\tLoss 0.5767\tAcc 79.97\n",
      "Test: [20/20]\tTime 0.1094\tData 0.0891\tLoss 0.6474\tAcc 77.97\n",
      "Epoch: [21]\n",
      "Train: [98/98]\tTime 0.0676\tData 0.0380\tLoss 0.5639\tAcc 80.18\n",
      "Test: [20/20]\tTime 0.1177\tData 0.0981\tLoss 0.6681\tAcc 77.53\n",
      "Epoch: [22]\n",
      "Train: [98/98]\tTime 0.0665\tData 0.0383\tLoss 0.5595\tAcc 80.44\n",
      "Test: [20/20]\tTime 0.1149\tData 0.0936\tLoss 0.7468\tAcc 76.18\n",
      "Epoch: [23]\n",
      "Train: [98/98]\tTime 0.0696\tData 0.0415\tLoss 0.5456\tAcc 80.97\n",
      "Test: [20/20]\tTime 0.1099\tData 0.0916\tLoss 0.6097\tAcc 79.41\n",
      "Epoch: [24]\n",
      "Train: [98/98]\tTime 0.0715\tData 0.0424\tLoss 0.5313\tAcc 81.52\n",
      "Test: [20/20]\tTime 0.1138\tData 0.0949\tLoss 0.7347\tAcc 75.71\n",
      "Epoch: [25]\n",
      "Train: [98/98]\tTime 0.0708\tData 0.0412\tLoss 0.5196\tAcc 81.83\n",
      "Test: [20/20]\tTime 0.1128\tData 0.0976\tLoss 0.6506\tAcc 77.94\n",
      "Epoch: [26]\n",
      "Train: [98/98]\tTime 0.0703\tData 0.0420\tLoss 0.5110\tAcc 82.17\n",
      "Test: [20/20]\tTime 0.1117\tData 0.1000\tLoss 0.6570\tAcc 77.47\n",
      "Epoch: [27]\n",
      "Train: [98/98]\tTime 0.0682\tData 0.0402\tLoss 0.5070\tAcc 82.37\n",
      "Test: [20/20]\tTime 0.1130\tData 0.0921\tLoss 0.6394\tAcc 78.26\n",
      "Epoch: [28]\n",
      "Train: [98/98]\tTime 0.0676\tData 0.0377\tLoss 0.4959\tAcc 82.78\n",
      "Test: [20/20]\tTime 0.1175\tData 0.0984\tLoss 0.6422\tAcc 77.86\n",
      "Epoch: [29]\n",
      "Train: [98/98]\tTime 0.0690\tData 0.0404\tLoss 0.4858\tAcc 83.02\n",
      "Test: [20/20]\tTime 0.1102\tData 0.0915\tLoss 0.6507\tAcc 78.16\n",
      "Epoch: [30]\n",
      "Train: [98/98]\tTime 0.0692\tData 0.0404\tLoss 0.4752\tAcc 83.36\n",
      "Test: [20/20]\tTime 0.1051\tData 0.0880\tLoss 0.6410\tAcc 78.53\n",
      "Epoch: [31]\n",
      "Train: [98/98]\tTime 0.0671\tData 0.0386\tLoss 0.4723\tAcc 83.34\n",
      "Test: [20/20]\tTime 0.1095\tData 0.0893\tLoss 0.6390\tAcc 78.96\n",
      "Epoch: [32]\n",
      "Train: [98/98]\tTime 0.0663\tData 0.0384\tLoss 0.4623\tAcc 83.85\n",
      "Test: [20/20]\tTime 0.1119\tData 0.0919\tLoss 0.5768\tAcc 80.61\n",
      "Epoch: [33]\n",
      "Train: [98/98]\tTime 0.0675\tData 0.0393\tLoss 0.4509\tAcc 84.26\n",
      "Test: [20/20]\tTime 0.1091\tData 0.0894\tLoss 0.5791\tAcc 80.70\n",
      "Epoch: [34]\n",
      "Train: [98/98]\tTime 0.0680\tData 0.0388\tLoss 0.4355\tAcc 84.88\n",
      "Test: [20/20]\tTime 0.1089\tData 0.0890\tLoss 0.6074\tAcc 80.20\n",
      "Epoch: [35]\n",
      "Train: [98/98]\tTime 0.0686\tData 0.0398\tLoss 0.4358\tAcc 84.91\n",
      "Test: [20/20]\tTime 0.1137\tData 0.0941\tLoss 0.5846\tAcc 80.14\n",
      "Epoch: [36]\n",
      "Train: [98/98]\tTime 0.0690\tData 0.0395\tLoss 0.4324\tAcc 84.89\n",
      "Test: [20/20]\tTime 0.1115\tData 0.0940\tLoss 0.6186\tAcc 79.43\n",
      "Epoch: [37]\n",
      "Train: [98/98]\tTime 0.0675\tData 0.0382\tLoss 0.4226\tAcc 85.18\n",
      "Test: [20/20]\tTime 0.1096\tData 0.0924\tLoss 0.7309\tAcc 76.03\n",
      "Epoch: [38]\n",
      "Train: [98/98]\tTime 0.0657\tData 0.0386\tLoss 0.4076\tAcc 85.72\n",
      "Test: [20/20]\tTime 0.1116\tData 0.0918\tLoss 0.6229\tAcc 79.56\n",
      "Epoch: [39]\n",
      "Train: [98/98]\tTime 0.0694\tData 0.0390\tLoss 0.4008\tAcc 85.95\n",
      "Test: [20/20]\tTime 0.1138\tData 0.0960\tLoss 0.5728\tAcc 81.16\n",
      "Epoch: [40]\n",
      "Train: [98/98]\tTime 0.0686\tData 0.0388\tLoss 0.3934\tAcc 86.12\n",
      "Test: [20/20]\tTime 0.1127\tData 0.0927\tLoss 0.6137\tAcc 79.97\n",
      "Epoch: [41]\n",
      "Train: [98/98]\tTime 0.0694\tData 0.0405\tLoss 0.3916\tAcc 86.23\n",
      "Test: [20/20]\tTime 0.1140\tData 0.0939\tLoss 0.6529\tAcc 79.16\n",
      "Epoch: [42]\n",
      "Train: [98/98]\tTime 0.0676\tData 0.0384\tLoss 0.3826\tAcc 86.59\n",
      "Test: [20/20]\tTime 0.1116\tData 0.0960\tLoss 0.7334\tAcc 77.14\n",
      "Epoch: [43]\n",
      "Train: [98/98]\tTime 0.0699\tData 0.0407\tLoss 0.3746\tAcc 86.73\n",
      "Test: [20/20]\tTime 0.1106\tData 0.0934\tLoss 0.6514\tAcc 79.12\n",
      "Epoch: [44]\n",
      "Train: [98/98]\tTime 0.0718\tData 0.0413\tLoss 0.3706\tAcc 87.07\n",
      "Test: [20/20]\tTime 0.1146\tData 0.0978\tLoss 0.5552\tAcc 81.63\n",
      "Epoch: [45]\n",
      "Train: [98/98]\tTime 0.0696\tData 0.0415\tLoss 0.3590\tAcc 87.21\n",
      "Test: [20/20]\tTime 0.1082\tData 0.0911\tLoss 0.6531\tAcc 79.28\n",
      "Epoch: [46]\n",
      "Train: [98/98]\tTime 0.0695\tData 0.0396\tLoss 0.3537\tAcc 87.59\n",
      "Test: [20/20]\tTime 0.1169\tData 0.0950\tLoss 0.5941\tAcc 80.79\n",
      "Epoch: [47]\n",
      "Train: [98/98]\tTime 0.0657\tData 0.0384\tLoss 0.3431\tAcc 88.01\n",
      "Test: [20/20]\tTime 0.1099\tData 0.0892\tLoss 0.5665\tAcc 81.69\n",
      "Epoch: [48]\n",
      "Train: [98/98]\tTime 0.0660\tData 0.0376\tLoss 0.3387\tAcc 88.09\n",
      "Test: [20/20]\tTime 0.1107\tData 0.0911\tLoss 0.6143\tAcc 80.33\n",
      "Epoch: [49]\n",
      "Train: [98/98]\tTime 0.0655\tData 0.0376\tLoss 0.3276\tAcc 88.45\n",
      "Test: [20/20]\tTime 0.1058\tData 0.0878\tLoss 0.5642\tAcc 81.75\n",
      "Epoch: [50]\n",
      "Train: [98/98]\tTime 0.0644\tData 0.0362\tLoss 0.3218\tAcc 88.76\n",
      "Test: [20/20]\tTime 0.1040\tData 0.0878\tLoss 0.5365\tAcc 82.72\n",
      "Epoch: [51]\n",
      "Train: [98/98]\tTime 0.0652\tData 0.0380\tLoss 0.3118\tAcc 89.04\n",
      "Test: [20/20]\tTime 0.1091\tData 0.0891\tLoss 0.5556\tAcc 82.46\n",
      "Epoch: [52]\n",
      "Train: [98/98]\tTime 0.0641\tData 0.0371\tLoss 0.3048\tAcc 89.21\n",
      "Test: [20/20]\tTime 0.1110\tData 0.0895\tLoss 0.5717\tAcc 82.09\n",
      "Epoch: [53]\n",
      "Train: [98/98]\tTime 0.0640\tData 0.0371\tLoss 0.3058\tAcc 89.25\n",
      "Test: [20/20]\tTime 0.1112\tData 0.0918\tLoss 0.5708\tAcc 81.84\n",
      "Epoch: [54]\n",
      "Train: [98/98]\tTime 0.0636\tData 0.0364\tLoss 0.2870\tAcc 89.86\n",
      "Test: [20/20]\tTime 0.1066\tData 0.0894\tLoss 0.5717\tAcc 82.58\n",
      "Epoch: [55]\n",
      "Train: [98/98]\tTime 0.0644\tData 0.0366\tLoss 0.2830\tAcc 89.96\n",
      "Test: [20/20]\tTime 0.1105\tData 0.0917\tLoss 0.5384\tAcc 83.07\n",
      "Epoch: [56]\n",
      "Train: [98/98]\tTime 0.0662\tData 0.0377\tLoss 0.2767\tAcc 90.32\n",
      "Test: [20/20]\tTime 0.1109\tData 0.0909\tLoss 0.5710\tAcc 82.33\n",
      "Epoch: [57]\n",
      "Train: [98/98]\tTime 0.0660\tData 0.0384\tLoss 0.2651\tAcc 90.66\n",
      "Test: [20/20]\tTime 0.1040\tData 0.0870\tLoss 0.5755\tAcc 82.64\n",
      "Epoch: [58]\n",
      "Train: [98/98]\tTime 0.0654\tData 0.0374\tLoss 0.2556\tAcc 90.99\n",
      "Test: [20/20]\tTime 0.1100\tData 0.0898\tLoss 0.5312\tAcc 83.29\n",
      "Epoch: [59]\n",
      "Train: [98/98]\tTime 0.0653\tData 0.0373\tLoss 0.2521\tAcc 91.13\n",
      "Test: [20/20]\tTime 0.1105\tData 0.0900\tLoss 0.5583\tAcc 82.89\n",
      "Epoch: [60]\n",
      "Train: [98/98]\tTime 0.0647\tData 0.0374\tLoss 0.2485\tAcc 91.24\n",
      "Test: [20/20]\tTime 0.1107\tData 0.0910\tLoss 0.5650\tAcc 83.00\n",
      "Epoch: [61]\n",
      "Train: [98/98]\tTime 0.0662\tData 0.0384\tLoss 0.2409\tAcc 91.48\n",
      "Test: [20/20]\tTime 0.1098\tData 0.0905\tLoss 0.5539\tAcc 83.41\n",
      "Epoch: [62]\n",
      "Train: [98/98]\tTime 0.0635\tData 0.0362\tLoss 0.2266\tAcc 91.94\n",
      "Test: [20/20]\tTime 0.1084\tData 0.0886\tLoss 0.5532\tAcc 83.65\n",
      "Epoch: [63]\n",
      "Train: [98/98]\tTime 0.0661\tData 0.0377\tLoss 0.2234\tAcc 92.09\n",
      "Test: [20/20]\tTime 0.1105\tData 0.0908\tLoss 0.5703\tAcc 83.16\n",
      "Epoch: [64]\n",
      "Train: [98/98]\tTime 0.0659\tData 0.0374\tLoss 0.2100\tAcc 92.59\n",
      "Test: [20/20]\tTime 0.1108\tData 0.0910\tLoss 0.5900\tAcc 83.20\n",
      "Epoch: [65]\n",
      "Train: [98/98]\tTime 0.0647\tData 0.0370\tLoss 0.2074\tAcc 92.65\n",
      "Test: [20/20]\tTime 0.1089\tData 0.0913\tLoss 0.5492\tAcc 83.78\n",
      "Epoch: [66]\n",
      "Train: [98/98]\tTime 0.0651\tData 0.0365\tLoss 0.1930\tAcc 93.09\n",
      "Test: [20/20]\tTime 0.1112\tData 0.0917\tLoss 0.5881\tAcc 83.07\n",
      "Epoch: [67]\n",
      "Train: [98/98]\tTime 0.0686\tData 0.0394\tLoss 0.1901\tAcc 93.21\n",
      "Test: [20/20]\tTime 0.1095\tData 0.0924\tLoss 0.5569\tAcc 83.78\n",
      "Epoch: [68]\n",
      "Train: [98/98]\tTime 0.0708\tData 0.0412\tLoss 0.1792\tAcc 93.69\n",
      "Test: [20/20]\tTime 0.1116\tData 0.0916\tLoss 0.5664\tAcc 83.67\n",
      "Epoch: [69]\n",
      "Train: [98/98]\tTime 0.0661\tData 0.0382\tLoss 0.1728\tAcc 93.86\n",
      "Test: [20/20]\tTime 0.1112\tData 0.0908\tLoss 0.5535\tAcc 84.20\n",
      "Epoch: [70]\n",
      "Train: [98/98]\tTime 0.0649\tData 0.0370\tLoss 0.1603\tAcc 94.39\n",
      "Test: [20/20]\tTime 0.1086\tData 0.0916\tLoss 0.5519\tAcc 84.40\n",
      "Epoch: [71]\n",
      "Train: [98/98]\tTime 0.0642\tData 0.0366\tLoss 0.1544\tAcc 94.47\n",
      "Test: [20/20]\tTime 0.1120\tData 0.0921\tLoss 0.6011\tAcc 83.86\n",
      "Epoch: [72]\n",
      "Train: [98/98]\tTime 0.0663\tData 0.0379\tLoss 0.1482\tAcc 94.82\n",
      "Test: [20/20]\tTime 0.1080\tData 0.0879\tLoss 0.5352\tAcc 85.34\n",
      "Epoch: [73]\n",
      "Train: [98/98]\tTime 0.0662\tData 0.0379\tLoss 0.1389\tAcc 95.12\n",
      "Test: [20/20]\tTime 0.1128\tData 0.0934\tLoss 0.5928\tAcc 84.18\n",
      "Epoch: [74]\n",
      "Train: [98/98]\tTime 0.0669\tData 0.0391\tLoss 0.1312\tAcc 95.47\n",
      "Test: [20/20]\tTime 0.1048\tData 0.0887\tLoss 0.5543\tAcc 84.96\n",
      "Epoch: [75]\n",
      "Train: [98/98]\tTime 0.0656\tData 0.0382\tLoss 0.1235\tAcc 95.69\n",
      "Test: [20/20]\tTime 0.1099\tData 0.0896\tLoss 0.5539\tAcc 85.19\n",
      "Epoch: [76]\n",
      "Train: [98/98]\tTime 0.0663\tData 0.0386\tLoss 0.1119\tAcc 96.18\n",
      "Test: [20/20]\tTime 0.1118\tData 0.0908\tLoss 0.5614\tAcc 85.25\n",
      "Epoch: [77]\n",
      "Train: [98/98]\tTime 0.0655\tData 0.0370\tLoss 0.1054\tAcc 96.31\n",
      "Test: [20/20]\tTime 0.1106\tData 0.0896\tLoss 0.5556\tAcc 85.40\n",
      "Epoch: [78]\n",
      "Train: [98/98]\tTime 0.0662\tData 0.0379\tLoss 0.0992\tAcc 96.57\n",
      "Test: [20/20]\tTime 0.1095\tData 0.0907\tLoss 0.5835\tAcc 85.22\n",
      "Epoch: [79]\n",
      "Train: [98/98]\tTime 0.0654\tData 0.0378\tLoss 0.0933\tAcc 96.84\n",
      "Test: [20/20]\tTime 0.1110\tData 0.0909\tLoss 0.5725\tAcc 85.88\n",
      "Epoch: [80]\n",
      "Train: [98/98]\tTime 0.0652\tData 0.0374\tLoss 0.0849\tAcc 97.06\n",
      "Test: [20/20]\tTime 0.1117\tData 0.0912\tLoss 0.5815\tAcc 85.13\n",
      "Epoch: [81]\n",
      "Train: [98/98]\tTime 0.0693\tData 0.0407\tLoss 0.0816\tAcc 97.18\n",
      "Test: [20/20]\tTime 0.1088\tData 0.0920\tLoss 0.5701\tAcc 85.47\n",
      "Epoch: [82]\n",
      "Train: [98/98]\tTime 0.0654\tData 0.0377\tLoss 0.0741\tAcc 97.49\n",
      "Test: [20/20]\tTime 0.1116\tData 0.0918\tLoss 0.5714\tAcc 86.01\n",
      "Epoch: [83]\n",
      "Train: [98/98]\tTime 0.0653\tData 0.0382\tLoss 0.0682\tAcc 97.67\n",
      "Test: [20/20]\tTime 0.1118\tData 0.0913\tLoss 0.5772\tAcc 85.64\n",
      "Epoch: [84]\n",
      "Train: [98/98]\tTime 0.0657\tData 0.0380\tLoss 0.0648\tAcc 97.81\n",
      "Test: [20/20]\tTime 0.1102\tData 0.0902\tLoss 0.5691\tAcc 86.14\n",
      "Epoch: [85]\n",
      "Train: [98/98]\tTime 0.0633\tData 0.0362\tLoss 0.0599\tAcc 98.02\n",
      "Test: [20/20]\tTime 0.1037\tData 0.0884\tLoss 0.5787\tAcc 85.97\n",
      "Epoch: [86]\n",
      "Train: [98/98]\tTime 0.0653\tData 0.0371\tLoss 0.0562\tAcc 98.14\n",
      "Test: [20/20]\tTime 0.1041\tData 0.0888\tLoss 0.5782\tAcc 86.27\n",
      "Epoch: [87]\n",
      "Train: [98/98]\tTime 0.0660\tData 0.0387\tLoss 0.0520\tAcc 98.26\n",
      "Test: [20/20]\tTime 0.1102\tData 0.0905\tLoss 0.5770\tAcc 86.43\n",
      "Epoch: [88]\n",
      "Train: [98/98]\tTime 0.0650\tData 0.0371\tLoss 0.0482\tAcc 98.40\n",
      "Test: [20/20]\tTime 0.1118\tData 0.0920\tLoss 0.5795\tAcc 86.13\n",
      "Epoch: [89]\n",
      "Train: [98/98]\tTime 0.0662\tData 0.0382\tLoss 0.0454\tAcc 98.48\n",
      "Test: [20/20]\tTime 0.1096\tData 0.0894\tLoss 0.5819\tAcc 86.37\n",
      "Epoch: [90]\n",
      "Train: [98/98]\tTime 0.0660\tData 0.0381\tLoss 0.0429\tAcc 98.58\n",
      "Test: [20/20]\tTime 0.1105\tData 0.0903\tLoss 0.5854\tAcc 86.40\n",
      "Epoch: [91]\n",
      "Train: [98/98]\tTime 0.0656\tData 0.0377\tLoss 0.0414\tAcc 98.60\n",
      "Test: [20/20]\tTime 0.1075\tData 0.0905\tLoss 0.5836\tAcc 86.55\n",
      "Epoch: [92]\n",
      "Train: [98/98]\tTime 0.0648\tData 0.0362\tLoss 0.0386\tAcc 98.76\n",
      "Test: [20/20]\tTime 0.1108\tData 0.0911\tLoss 0.5892\tAcc 86.17\n",
      "Epoch: [93]\n",
      "Train: [98/98]\tTime 0.0664\tData 0.0380\tLoss 0.0391\tAcc 98.77\n",
      "Test: [20/20]\tTime 0.1088\tData 0.0891\tLoss 0.5872\tAcc 86.27\n",
      "Epoch: [94]\n",
      "Train: [98/98]\tTime 0.0663\tData 0.0387\tLoss 0.0354\tAcc 98.86\n",
      "Test: [20/20]\tTime 0.1082\tData 0.0886\tLoss 0.5857\tAcc 86.26\n",
      "Epoch: [95]\n",
      "Train: [98/98]\tTime 0.0662\tData 0.0376\tLoss 0.0357\tAcc 98.91\n",
      "Test: [20/20]\tTime 0.1095\tData 0.0893\tLoss 0.5877\tAcc 86.32\n",
      "Epoch: [96]\n",
      "Train: [98/98]\tTime 0.0645\tData 0.0372\tLoss 0.0358\tAcc 98.84\n",
      "Test: [20/20]\tTime 0.1078\tData 0.0882\tLoss 0.5875\tAcc 86.41\n",
      "Epoch: [97]\n",
      "Train: [98/98]\tTime 0.0663\tData 0.0378\tLoss 0.0353\tAcc 98.89\n",
      "Test: [20/20]\tTime 0.1092\tData 0.0885\tLoss 0.5840\tAcc 86.40\n",
      "Epoch: [98]\n",
      "Train: [98/98]\tTime 0.0642\tData 0.0373\tLoss 0.0341\tAcc 98.96\n",
      "Test: [20/20]\tTime 0.1113\tData 0.0918\tLoss 0.5875\tAcc 86.43\n",
      "Epoch: [99]\n",
      "Train: [98/98]\tTime 0.0658\tData 0.0377\tLoss 0.0356\tAcc 98.87\n",
      "Test: [20/20]\tTime 0.1111\tData 0.0911\tLoss 0.5885\tAcc 86.44\n",
      "\n",
      "Finished Training\n",
      "\n",
      "Total Average Training Time : 6.54 ± 0.37 sec\n",
      "Total Average Validation Time : 2.28 ± 0.08 sec\n",
      "\n",
      "Total Best Validation Accuracy : 86.55 %\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "train_time = []\n",
    "val_time = []\n",
    "\n",
    "for idx in range(epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    # train for one epoch\n",
    "    end = time.time()\n",
    "    train(train_loader, model, criterion, optimizer, idx, device)\n",
    "    train_time.append(time.time() - end)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    end = time.time()\n",
    "    acc = validate(val_loader, model, criterion, device)\n",
    "    val_time.append(time.time() - end)\n",
    "\n",
    "    # remember best acc and save checkpoint\n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "\n",
    "    save_checkpoint({\n",
    "            'epoch': idx + 1,\n",
    "            'arch': \"ResNet-18\",\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "train_time = np.array(train_time)\n",
    "val_time = np.array(val_time)\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Average Training Time : %.2f ± %.2f\" % (train_time.mean(), train_time.std()), \"sec\")\n",
    "print(\"Total Average Validation Time : %.2f ± %.2f\" % (val_time.mean(), val_time.std()), \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % best_acc.real, \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch = 10\n",
    "num_class = 10\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_feature = model.fc.in_features\n",
    "lda = LinearDiscriminantAnalysis(n_com)\n",
    "model.fc = nn.Linear(num_feature, num_class)\n",
    "model.to(device)\n",
    "\n",
    "feature_extract = True\n",
    "\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_acc = 0.\n",
    "train_time = []\n",
    "val_time = []\n",
    "\n",
    "for idx in range(epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    # train for one epoch\n",
    "    end = time.time()\n",
    "    train(train_loader, model, criterion, optimizer, idx, device)\n",
    "    train_time.append(time.time() - end)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    end = time.time()\n",
    "    acc = validate(val_loader, model, criterion, device)\n",
    "    val_time.append(time.time() - end)\n",
    "\n",
    "    # remember best acc and save checkpoint\n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "\n",
    "    save_checkpoint({\n",
    "            'epoch': idx + 1,\n",
    "            'arch': \"ResNet-18\",\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "train_time = np.array(train_time)\n",
    "val_time = np.array(val_time)\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Average Training Time : %.2f ± %.2f\" % (train_time.mean(), train_time.std()), \"sec\")\n",
    "print(\"Total Average Validation Time : %.2f ± %.2f\" % (val_time.mean(), val_time.std()), \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % best_acc.real, \"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
