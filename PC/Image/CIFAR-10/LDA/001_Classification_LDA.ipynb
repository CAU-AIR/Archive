{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFA-10 Dataset Classification using Linear Discriminant Analysis (LDA)\n",
    "\n",
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\_distributor_init.py:30: UserWarning: loaded more than 1 DLL from .libs:\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.EL2C6PLE4ZYW3ECEVIV3OXXGRN2NRFM2.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.WCDJNK7YVMPZQ2ME2ZZHJJRJ3JIKNDB7.gfortran-win_amd64.dll\n",
      "c:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\numpy\\.libs\\libopenblas.XWYDX2IKJW2NMTWSFYNGFUWKQU3LYTCZ.gfortran-win_amd64.dll\n",
      "  warnings.warn(\"loaded more than 1 DLL from .libs:\"\n",
      "<frozen importlib._bootstrap>:219: RuntimeWarning: scipy._lib.messagestream.MessageStream size changed, may indicate binary incompatibility. Expected 56 from C header, got 64 from PyObject\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils import Info\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(Info):\n",
    "    def __init__(self):\n",
    "        super(Info, self).__init__()\n",
    "        self.device = 'PC'\n",
    "        self.dataset = 'CIFAR-10'\n",
    "        self.test_size = 0.2\n",
    "        self.feature_size = 3072\n",
    "        self.method = 'LDA'\n",
    "        self.reduction_method = [None, None] # method, n_components\n",
    "        self.reduction_ratio = None\n",
    "        self.iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────CIFAR-10\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────LDA\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: None\n",
      "│    └────Component size: None\n",
      "│    └────Feature Reduction Ratio: None\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "cig = Config()\n",
    "cig.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFA-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "print(testset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "features = trainset.data.reshape(-1, cig.feature_size)\n",
    "target = trainset.targets\n",
    "\n",
    "features = features / 255.\n",
    "\n",
    "print(np.array(features).shape)\n",
    "print(np.array(target).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_acc = []\n",
    "comparison_lda_time = []\n",
    "comparison_time = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC - CIFAR-10(80%) - LDA - 10 iteration\n",
      "----------------------------------------\n",
      "Test set score: 0.3608\n",
      "All Test dataset Prediction Average Time at once : 52226.4600 sec\n",
      "Divide the Prediction Time by Test size : 5.2226 ms\n"
     ]
    }
   ],
   "source": [
    "avg_acc = []\n",
    "avg_time = []\n",
    "\n",
    "max_seed = cig.iter\n",
    "\n",
    "for seed in range(max_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=cig.test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()  # default = svd\n",
    "    lda.fit(x_train, y_train)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    test_score = lda.score(x_test, y_test)\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    avg_acc.append(test_score)\n",
    "    avg_time.append(end)\n",
    "\n",
    "mean_acc = np.array(avg_acc).mean()\n",
    "mean_time = np.array(avg_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "comparison_acc.append(mean_acc)\n",
    "comparison_time.append(mean_time)\n",
    "\n",
    "cig.print_rutin()\n",
    "print(\"-----\" * 8)\n",
    "print(\"Test set score: %.4f\" % mean_acc)\n",
    "print(\"All Test dataset Prediction Average Time at once : %.4f\" % (mean_time*len(y_test)), \"sec\")\n",
    "print(\"Divide the Prediction Time by Test size : %.4f\" % mean_time, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA with Dimensijon Reduction (Feature 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────CIFAR-10\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────LDA\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: LDA\n",
      "│    └────Component size: 9\n",
      "│    └────Feature Reduction Ratio: 0.3%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "cig.reduction_method = ['LDA', 9]\n",
    "cig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 2 features, but LinearDiscriminantAnalysis is expecting 3072 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-bc19a59f36b9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     31\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     32\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 33\u001b[1;33m     \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     34\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mperf_counter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    704\u001b[0m         \"\"\"\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# Only override for the doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 2 features, but LinearDiscriminantAnalysis is expecting 3072 features as input."
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "avg_acc = []\n",
    "avg_lda_time = []\n",
    "avg_train_project_time = []\n",
    "avg_test_project_time = []\n",
    "avg_time = []\n",
    "\n",
    "max_seed = cig.iter\n",
    "\n",
    "for seed in range(max_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=cig.test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=cig.reduction_method[1])  # default = svd\n",
    "\n",
    "    lda_start = time.perf_counter()\n",
    "    lda.fit_transform(x_train, y_train)\n",
    "    lda_end = time.perf_counter() - lda_start\n",
    "    avg_lda_time.append(lda_end)\n",
    "\n",
    "    # lda_p_start = time.perf_counter()\n",
    "    # x_train = lda.transform(x_train)\n",
    "    # lda_p_end = time.perf_counter() - lda_p_start\n",
    "    # avg_train_project_time.append(lda_p_end)\n",
    "\n",
    "    lda_p_start = time.perf_counter()\n",
    "    x_test = lda.transform(x_test)\n",
    "    lda_p_end = time.perf_counter() - lda_p_start\n",
    "    avg_test_project_time.append(lda_p_end)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    test_score = lda.score(x_test, y_test)\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    avg_acc.append(test_score)\n",
    "    avg_time.append(end)\n",
    "\n",
    "mean_lda_time = np.array(avg_lda_time).mean()\n",
    "mean_train_project = np.array(avg_train_project_time).mean()\n",
    "mean_test_project = np.array(avg_test_project_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "mean_acc = np.array(avg_acc).mean()\n",
    "mean_time = np.array(avg_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "comparison_acc.append(mean_acc)\n",
    "comparison_lda_time.append(mean_test_project)\n",
    "comparison_time.append(mean_time)\n",
    "\n",
    "cig.print_rutin()\n",
    "print(\"-----\" * 8)\n",
    "print(\"The number of components : %d(%f%)\" % cig.reduction_method[1], cig.reduction_ratio)\n",
    "print(\"Calculating Train dataset U*S*Vt Matrix Time : %.4f\" % mean_lda_time, \"sec\")\n",
    "print(\"Calculating Train dataset Projection Time : %.4f\" % mean_train_project, \"sec\")\n",
    "print(\"All Test dataset Projection Time : %.4f\" % (mean_test_project*len(y_test)), \"sec\")\n",
    "print(\"Divide the Projection Time by Test size : %f\" % mean_test_project, \"ms\")\n",
    "print(\"-----\" * 8)\n",
    "print(\"Test set score: %f\" % mean_acc)\n",
    "print(\"All Test dataset Prediction Average Time at once : %.4f\" % (mean_time*len(y_test)), \"sec\")\n",
    "print(\"Divide the Prediction Time by Test size : %.4f\" % mean_time, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN with LDA Dimensijon Reduction (Feature 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────CIFAR-10\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────LDA\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: LDA\n",
      "│    └────Component size: 9\n",
      "│    └────Feature Reduction Ratio: 0.3%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "cig.reduction_method = ['LDA', 9]\n",
    "cig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC - CIFAR-10(80%) - LDA - 10 iteration - LDA(reduction : 9%)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not enough arguments for format string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-376fb989806f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mcig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_rutin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The number of components : %d(%f%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction_method\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating Train dataset U*S*Vt Matrix Time : %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmean_lda_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating Train dataset Projection Time : %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmean_train_project\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: not enough arguments for format string"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "avg_acc = []\n",
    "avg_lda_time = []\n",
    "avg_train_project_time = []\n",
    "avg_test_project_time = []\n",
    "avg_time = []\n",
    "\n",
    "max_seed = cig.iter\n",
    "\n",
    "for seed in range(max_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=cig.test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=cig.reduction_method[1])  # default = svd\n",
    "\n",
    "    lda_start = time.perf_counter()\n",
    "    lda.fit(x_train, y_train)\n",
    "    lda_end = time.perf_counter() - lda_start\n",
    "    avg_lda_time.append(lda_end)\n",
    "\n",
    "    lda_p_start = time.perf_counter()\n",
    "    x_train = lda.transform(x_train)\n",
    "    lda_p_end = time.perf_counter() - lda_p_start\n",
    "    avg_train_project_time.append(lda_p_end)\n",
    "\n",
    "    knn = KNeighborsClassifier(1, weights='distance', n_jobs=-1)\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    lda_p_start = time.perf_counter()\n",
    "    x_test = lda.transform(x_test)\n",
    "    lda_p_end = time.perf_counter() - lda_p_start\n",
    "    avg_test_project_time.append(lda_p_end)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    test_score = knn.score(x_test, y_test)\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    avg_acc.append(test_score)\n",
    "    avg_time.append(end)\n",
    "\n",
    "\n",
    "mean_lda_time = np.array(avg_lda_time).mean()\n",
    "mean_train_project = np.array(avg_train_project_time).mean()\n",
    "mean_test_project = np.array(avg_test_project_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "mean_acc = np.array(avg_acc).mean()\n",
    "mean_time = np.array(avg_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "comparison_acc.append(mean_acc)\n",
    "comparison_lda_time.append(mean_test_project)\n",
    "comparison_time.append(mean_time)\n",
    "\n",
    "cig.print_rutin()\n",
    "print(\"-----\" * 8)\n",
    "print(\"The number of components : %d(%f%)\" % cig.reduction_method[1], cig.reduction_ratio)\n",
    "print(\"Calculating Train dataset U*S*Vt Matrix Time : %.4f\" % mean_lda_time, \"sec\")\n",
    "print(\"Calculating Train dataset Projection Time : %.4f\" % mean_train_project, \"sec\")\n",
    "print(\"All Test dataset Projection Time : %.4f\" % (mean_test_project*len(y_test)), \"sec\")\n",
    "print(\"Divide the Projection Time by Test size : %f\" % mean_test_project, \"ms\")\n",
    "print(\"-----\" * 8)\n",
    "print(\"Test set score: %f\" % mean_acc)\n",
    "print(\"All Test dataset Prediction Average Time at once : %.4f\" % (mean_time*len(y_test)), \"sec\")\n",
    "print(\"Divide the Prediction Time by Test size : %.4f\" % mean_time, \"ms\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "730f0a366f938e2b20db2e10f7d964c3cd988921f1021d5f226cdeb03c378907"
  },
  "kernelspec": {
   "display_name": "lab",
   "language": "python",
   "name": "lab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
