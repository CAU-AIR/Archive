{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CIFA-10 Dataset Classification using Linear Discriminant Analysis (LDA)\n",
    "\n",
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from utils.util import Info\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier, NearestCentroid\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(Info):\n",
    "    def __init__(self):\n",
    "        super(Info, self).__init__()\n",
    "        self.device = 'PC'\n",
    "        self.dataset = 'CIFAR-10'\n",
    "        self.test_size = 0.2\n",
    "        self.feature_size = 3072\n",
    "        self.method = 'LDA'\n",
    "        self.reduction_method = [None, None] # method, n_components\n",
    "        self.reduction_ratio = None\n",
    "        self.iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────CIFAR-10\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────LDA\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: None\n",
      "│    └────Component size: None\n",
      "│    └────Feature Reduction Ratio: None%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "cig = Config()\n",
    "cig.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFA-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "batch_size = 4\n",
    "\n",
    "trainset = datasets.CIFAR10(root='../data', train=True, download=True, transform=transform)\n",
    "trainloader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = datasets.CIFAR10(root='../data', train=False, download=True, transform=transform)\n",
    "testloader = DataLoader(testset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "print(testset.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 3072)\n",
      "(50000,)\n"
     ]
    }
   ],
   "source": [
    "features = trainset.data.reshape(-1, cig.feature_size)\n",
    "target = trainset.targets\n",
    "\n",
    "features = features / 255.\n",
    "\n",
    "print(np.array(features).shape)\n",
    "print(np.array(target).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_acc = []\n",
    "comparison_lda_time = []\n",
    "comparison_time = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Discriminant Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC - CIFAR-10(80%) - LDA - 10 iteration\n",
      "----------------------------------------\n",
      "Test set score: 0.3608\n",
      "All Test dataset Prediction Average Time at once : 64864.9300 sec\n",
      "Divide the Prediction Time by Test size : 6.4865 ms\n"
     ]
    }
   ],
   "source": [
    "avg_acc = []\n",
    "avg_time = []\n",
    "\n",
    "max_seed = cig.iter\n",
    "\n",
    "for seed in range(max_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=cig.test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()  # default = svd\n",
    "    lda.fit(x_train, y_train)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    test_score = lda.score(x_test, y_test)\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    avg_acc.append(test_score)\n",
    "    avg_time.append(end)\n",
    "\n",
    "mean_acc = np.array(avg_acc).mean()\n",
    "mean_time = np.array(avg_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "comparison_acc.append(mean_acc)\n",
    "comparison_time.append(mean_time)\n",
    "\n",
    "cig.print_rutin()\n",
    "print(\"-----\" * 8)\n",
    "print(\"Test set score: %.4f\" % mean_acc)\n",
    "print(\"All Test dataset Prediction Average Time at once : %.4f\" % (mean_time*len(y_test)), \"sec\")\n",
    "print(\"Divide the Prediction Time by Test size : %.4f\" % mean_time, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA with Dimension Reduction (Feature 2,304) (75%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────CIFAR-10\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────LDA\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: PCA\n",
      "│    └────Component size: 2304\n",
      "│    └────Feature Reduction Ratio: 75.0%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "cig.reduction_method = ['PCA', 2304]\n",
    "cig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC - CIFAR-10(80%) - LDA - 10 iteration - PCA(feature 2304)\n",
      "----------------------------------------\n",
      "Calculating Train dataset U*S*Vt Matrix Time : 66.9630 sec\n",
      "Calculating Train dataset Projection Time : 3.4375 sec\n",
      "All Test dataset Projection Time : 785543.0400 sec\n",
      "Divide the Projection Time by Test size : 78.554304 ms\n",
      "----------------------------------------\n",
      "Test set score: 0.375050\n",
      "All Test dataset Prediction Average Time at once : 53000.9900 sec\n",
      "Divide the Prediction Time by Test size : 5.3001 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "avg_acc = []\n",
    "avg_pca_time = []\n",
    "avg_train_project_time = []\n",
    "avg_test_project_time = []\n",
    "avg_time = []\n",
    "\n",
    "max_seed = cig.iter\n",
    "\n",
    "for seed in range(max_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=cig.test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()  # default = svd\n",
    "\n",
    "    pca = PCA(n_components=cig.reduction_method[1], random_state=seed)\n",
    "    pca_start = time.perf_counter()\n",
    "    pca.fit(x_train)\n",
    "    pca_end = time.perf_counter() - pca_start\n",
    "    avg_pca_time.append(pca_end)\n",
    "\n",
    "    pca_p_start = time.perf_counter()\n",
    "    x_train = pca.transform(x_train)\n",
    "    pca_p_end = time.perf_counter() - pca_p_start\n",
    "    avg_train_project_time.append(pca_p_end)\n",
    "\n",
    "    lda.fit(x_train, y_train)\n",
    "\n",
    "    pca_p_start = time.perf_counter()\n",
    "    x_test = pca.transform(x_test)\n",
    "    pca_p_end = time.perf_counter() - pca_p_start\n",
    "    avg_test_project_time.append(pca_p_end)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    test_score = lda.score(x_test, y_test)\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    avg_acc.append(test_score)\n",
    "    avg_time.append(end)\n",
    "\n",
    "mean_lda_time = np.array(avg_pca_time).mean()\n",
    "mean_train_project = np.array(avg_train_project_time).mean()\n",
    "mean_test_project = np.array(avg_test_project_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "mean_acc = np.array(avg_acc).mean()\n",
    "mean_time = np.array(avg_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "comparison_acc.append(mean_acc)\n",
    "comparison_lda_time.append(mean_test_project)\n",
    "comparison_time.append(mean_time)\n",
    "\n",
    "cig.print_rutin()\n",
    "print(\"-----\" * 8)\n",
    "# print(\"The number of components : %d(%f%)\" % cig.reduction_method[1], cig.reduction_ratio)\n",
    "print(\"Calculating Train dataset U*S*Vt Matrix Time : %.4f\" % mean_lda_time, \"sec\")\n",
    "print(\"Calculating Train dataset Projection Time : %.4f\" % mean_train_project, \"sec\")\n",
    "print(\"All Test dataset Projection Time : %.4f\" % (mean_test_project*len(y_test)), \"sec\")\n",
    "print(\"Divide the Projection Time by Test size : %f\" % mean_test_project, \"ms\")\n",
    "print(\"-----\" * 8)\n",
    "print(\"Test set score: %f\" % mean_acc)\n",
    "print(\"All Test dataset Prediction Average Time at once : %.4f\" % (mean_time*len(y_test)), \"sec\")\n",
    "print(\"Divide the Prediction Time by Test size : %.4f\" % mean_time, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA with Dimension Reduction (Feature 512) (16.7%)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────CIFAR-10\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────LDA\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: PCA\n",
      "│    └────Component size: 512\n",
      "│    └────Feature Reduction Ratio: 16.7%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "cig.reduction_method = ['PCA', 512]\n",
    "cig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC - CIFAR-10(80%) - LDA - 10 iteration - PCA(feature 512)\n",
      "----------------------------------------\n",
      "Calculating Train dataset U*S*Vt Matrix Time : 11.3996 sec\n",
      "Calculating Train dataset Projection Time : 1.2722 sec\n",
      "All Test dataset Projection Time : 271927.0200 sec\n",
      "Divide the Projection Time by Test size : 27.192702 ms\n",
      "----------------------------------------\n",
      "Test set score: 0.410760\n",
      "All Test dataset Prediction Average Time at once : 14529.3400 sec\n",
      "Divide the Prediction Time by Test size : 1.4529 ms\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "avg_acc = []\n",
    "avg_pca_time = []\n",
    "avg_train_project_time = []\n",
    "avg_test_project_time = []\n",
    "avg_time = []\n",
    "\n",
    "max_seed = cig.iter\n",
    "\n",
    "for seed in range(max_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=cig.test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis()  # default = svd\n",
    "\n",
    "    pca = PCA(n_components=cig.reduction_method[1], random_state=seed)\n",
    "    pca_start = time.perf_counter()\n",
    "    pca.fit(x_train)\n",
    "    pca_end = time.perf_counter() - pca_start\n",
    "    avg_pca_time.append(pca_end)\n",
    "\n",
    "    pca_p_start = time.perf_counter()\n",
    "    x_train = pca.transform(x_train)\n",
    "    pca_p_end = time.perf_counter() - pca_p_start\n",
    "    avg_train_project_time.append(pca_p_end)\n",
    "\n",
    "    lda.fit(x_train, y_train)\n",
    "\n",
    "    pca_p_start = time.perf_counter()\n",
    "    x_test = pca.transform(x_test)\n",
    "    pca_p_end = time.perf_counter() - pca_p_start\n",
    "    avg_test_project_time.append(pca_p_end)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    test_score = lda.score(x_test, y_test)\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    avg_acc.append(test_score)\n",
    "    avg_time.append(end)\n",
    "\n",
    "mean_lda_time = np.array(avg_pca_time).mean()\n",
    "mean_train_project = np.array(avg_train_project_time).mean()\n",
    "mean_test_project = np.array(avg_test_project_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "mean_acc = np.array(avg_acc).mean()\n",
    "mean_time = np.array(avg_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "comparison_acc.append(mean_acc)\n",
    "comparison_lda_time.append(mean_test_project)\n",
    "comparison_time.append(mean_time)\n",
    "\n",
    "cig.print_rutin()\n",
    "print(\"-----\" * 8)\n",
    "# print(\"The number of components : %d(%f%)\" % cig.reduction_method[1], cig.reduction_ratio)\n",
    "print(\"Calculating Train dataset U*S*Vt Matrix Time : %.4f\" % mean_lda_time, \"sec\")\n",
    "print(\"Calculating Train dataset Projection Time : %.4f\" % mean_train_project, \"sec\")\n",
    "print(\"All Test dataset Projection Time : %.4f\" % (mean_test_project*len(y_test)), \"sec\")\n",
    "print(\"Divide the Projection Time by Test size : %f\" % mean_test_project, \"ms\")\n",
    "print(\"-----\" * 8)\n",
    "print(\"Test set score: %f\" % mean_acc)\n",
    "print(\"All Test dataset Prediction Average Time at once : %.4f\" % (mean_time*len(y_test)), \"sec\")\n",
    "print(\"Divide the Prediction Time by Test size : %.4f\" % mean_time, \"ms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## kNN with LDA Dimensijon Reduction (Feature 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device ── PC\n",
      "│\n",
      "├──Dataset\n",
      "│    └────CIFAR-10\n",
      "│    └────Train size 80%\n",
      "│    └────Feature size: 3072\n",
      "│\n",
      "├──Method\n",
      "│    └────LDA\n",
      "│\n",
      "├──Dimension reduction\n",
      "│    └────Method: LDA\n",
      "│    └────Component size: 9\n",
      "│    └────Feature Reduction Ratio: 0.3%\n",
      "│\n",
      "└──Iteration\n",
      "    └────10\n"
     ]
    }
   ],
   "source": [
    "cig.reduction_method = ['LDA', 9]\n",
    "cig.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PC - CIFAR-10(80%) - LDA - 10 iteration - LDA(reduction : 9%)\n",
      "----------------------------------------\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "not enough arguments for format string",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-376fb989806f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     53\u001b[0m \u001b[0mcig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_rutin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"-----\"\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 55\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"The number of components : %d(%f%)\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mcig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction_method\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction_ratio\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     56\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating Train dataset U*S*Vt Matrix Time : %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmean_lda_time\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     57\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Calculating Train dataset Projection Time : %.4f\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mmean_train_project\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"sec\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: not enough arguments for format string"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "avg_acc = []\n",
    "avg_lda_time = []\n",
    "avg_train_project_time = []\n",
    "avg_test_project_time = []\n",
    "avg_time = []\n",
    "\n",
    "max_seed = cig.iter\n",
    "\n",
    "for seed in range(max_seed):\n",
    "    x_train, x_test, y_train, y_test = train_test_split(features, target, test_size=cig.test_size, random_state=seed, shuffle=True)\n",
    "\n",
    "    lda = LinearDiscriminantAnalysis(n_components=cig.reduction_method[1])  # default = svd\n",
    "\n",
    "    lda_start = time.perf_counter()\n",
    "    lda.fit(x_train, y_train)\n",
    "    lda_end = time.perf_counter() - lda_start\n",
    "    avg_lda_time.append(lda_end)\n",
    "\n",
    "    lda_p_start = time.perf_counter()\n",
    "    x_train = lda.transform(x_train)\n",
    "    lda_p_end = time.perf_counter() - lda_p_start\n",
    "    avg_train_project_time.append(lda_p_end)\n",
    "\n",
    "    knn = KNeighborsClassifier(1, weights='distance', n_jobs=-1)\n",
    "    knn.fit(x_train, y_train)\n",
    "\n",
    "    lda_p_start = time.perf_counter()\n",
    "    x_test = lda.transform(x_test)\n",
    "    lda_p_end = time.perf_counter() - lda_p_start\n",
    "    avg_test_project_time.append(lda_p_end)\n",
    "\n",
    "    start = time.perf_counter()\n",
    "    test_score = knn.score(x_test, y_test)\n",
    "    end = time.perf_counter() - start\n",
    "\n",
    "    avg_acc.append(test_score)\n",
    "    avg_time.append(end)\n",
    "\n",
    "\n",
    "mean_lda_time = np.array(avg_lda_time).mean()\n",
    "mean_train_project = np.array(avg_train_project_time).mean()\n",
    "mean_test_project = np.array(avg_test_project_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "mean_acc = np.array(avg_acc).mean()\n",
    "mean_time = np.array(avg_time).mean() / len(y_test) * 1e6\n",
    "\n",
    "comparison_acc.append(mean_acc)\n",
    "comparison_lda_time.append(mean_test_project)\n",
    "comparison_time.append(mean_time)\n",
    "\n",
    "cig.print_rutin()\n",
    "print(\"-----\" * 8)\n",
    "print(\"The number of components : %d(%f%)\" % cig.reduction_method[1], cig.reduction_ratio)\n",
    "print(\"Calculating Train dataset U*S*Vt Matrix Time : %.4f\" % mean_lda_time, \"sec\")\n",
    "print(\"Calculating Train dataset Projection Time : %.4f\" % mean_train_project, \"sec\")\n",
    "print(\"All Test dataset Projection Time : %.4f\" % (mean_test_project*len(y_test)), \"sec\")\n",
    "print(\"Divide the Projection Time by Test size : %f\" % mean_test_project, \"ms\")\n",
    "print(\"-----\" * 8)\n",
    "print(\"Test set score: %f\" % mean_acc)\n",
    "print(\"All Test dataset Prediction Average Time at once : %.4f\" % (mean_time*len(y_test)), \"sec\")\n",
    "print(\"Divide the Prediction Time by Test size : %.4f\" % mean_time, \"ms\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
