{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using CNN and NCM for CIFAR-10 feature extraction and classification\n",
    "\n",
    "### Summary\n",
    "CIFAR-10 데이터셋을 분류하기 위해 CNN을 이용하여 데이터셋에 대한 특징을 추출 후 NCM을 이용하여 각 class에 대한 평균 값을 이용하여 분류\n",
    "\n",
    "<span style=\"color: #2D3748; background-color:#fff5b1;\">Test size를 0.2로 10번 반복 실험한 결과 평균적으로 0.34의 정확도를 보여주고 있고, test 데이터 1개를 분류하는데 0.0011초의 시간이 걸린다.</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.backends.cudnn as cudnn\n",
    "from utils.util import Info\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.models import resnet18\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from utils.Data_Classifier import train, validate, save_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(Info):\n",
    "    def __init__(self):\n",
    "        super(Info, self).__init__()\n",
    "        self.device = 'PC'\n",
    "        self.dataset = 'CIFAR_10'\n",
    "        self.test_size = 0.2\n",
    "        self.feature_size = 3072\n",
    "        self.method = 'CNN'\n",
    "        self.iter = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cig = Config()\n",
    "# cig.info()\n",
    "# cig.print_rutin()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 0\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "# torch.cuda.manual_seed_all(seed) # if use multi-GPU\n",
    "cudnn.deterministic = True  # 연산 처리 속도 감소 -> 모델과 코드를 배포해야 하는 연구 후반 단계에 사용\n",
    "cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load CIFAR-10 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "(50000, 32, 32, 3)\n",
      "(10000, 32, 32, 3)\n"
     ]
    }
   ],
   "source": [
    "transform_train = transforms.Compose([transforms.Resize(224),\n",
    "                                      transforms.RandomHorizontalFlip(),\n",
    "                                      transforms.ToTensor(),\n",
    "                                      transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                      ])\n",
    "\n",
    "transform_test = transforms.Compose([transforms.Resize(224),\n",
    "                                     transforms.ToTensor(),                                     \n",
    "                                     transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))\n",
    "                                     ])\n",
    "\n",
    "batch_size = 512\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='../data', train=True, download=True, transform=transform_train)\n",
    "train_loader = DataLoader(trainset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "validationset = torchvision.datasets.CIFAR10(root='../data', train=False, download=True, transform=transform_test)\n",
    "val_loader = DataLoader(validationset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print(trainset.data.shape)\n",
    "print(validationset.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params to learn:\n",
      "\t fc.weight\n",
      "\t fc.bias\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "epoch = 10\n",
    "num_class = 10\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_feature = model.fc.in_features\n",
    "model.fc = nn.Linear(num_feature, num_class)\n",
    "model.to(device)\n",
    "\n",
    "feature_extract = True\n",
    "\n",
    "params_to_update = model.parameters()\n",
    "print(\"Params to learn:\")\n",
    "if feature_extract:\n",
    "    params_to_update = []\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            params_to_update.append(param)\n",
    "            print(\"\\t\",name)\n",
    "else:\n",
    "    for name,param in model.named_parameters():\n",
    "        if param.requires_grad == True:\n",
    "            print(\"\\t\",name)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(params_to_update, lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0]\n",
      "Train: [98/98]\tTime 0.3971\tData 0.0558\tLoss 1.9159\tAcc 67.76\n",
      "Test: [20/20]\tTime 0.4406\tData 0.1264\tLoss 0.8629\tAcc 77.31\n",
      "Epoch: [1]\n",
      "Train: [98/98]\tTime 0.4356\tData 0.0571\tLoss 0.7673\tAcc 77.53\n",
      "Test: [20/20]\tTime 0.4820\tData 0.1441\tLoss 0.7883\tAcc 76.18\n",
      "Epoch: [2]\n",
      "Train: [98/98]\tTime 0.4100\tData 0.0553\tLoss 0.6762\tAcc 78.38\n",
      "Test: [20/20]\tTime 0.4669\tData 0.1295\tLoss 0.7598\tAcc 76.33\n",
      "Epoch: [3]\n",
      "Train: [98/98]\tTime 0.4730\tData 0.0793\tLoss 0.6269\tAcc 79.16\n",
      "Test: [20/20]\tTime 0.4955\tData 0.1477\tLoss 0.7059\tAcc 76.88\n",
      "Epoch: [4]\n",
      "Train: [98/98]\tTime 0.4806\tData 0.0820\tLoss 0.6351\tAcc 79.00\n",
      "Test: [20/20]\tTime 0.6326\tData 0.1505\tLoss 0.7608\tAcc 76.48\n",
      "Epoch: [5]\n",
      "Train: [98/98]\tTime 0.4806\tData 0.0975\tLoss 0.6394\tAcc 79.17\n",
      "Test: [20/20]\tTime 0.4944\tData 0.1518\tLoss 0.6506\tAcc 78.98\n",
      "Epoch: [6]\n",
      "Train: [98/98]\tTime 0.4781\tData 0.0836\tLoss 0.6824\tAcc 78.25\n",
      "Test: [20/20]\tTime 0.4274\tData 0.1401\tLoss 0.9444\tAcc 73.43\n",
      "Epoch: [7]\n",
      "Train: [98/98]\tTime 0.3801\tData 0.0533\tLoss 0.6610\tAcc 78.93\n",
      "Test: [20/20]\tTime 0.5099\tData 0.1286\tLoss 0.7062\tAcc 77.67\n",
      "Epoch: [8]\n",
      "Train: [98/98]\tTime 0.4695\tData 0.1061\tLoss 0.6387\tAcc 79.11\n",
      "Test: [20/20]\tTime 0.5111\tData 0.1509\tLoss 0.6074\tAcc 80.27\n",
      "Epoch: [9]\n",
      "Train: [98/98]\tTime 0.4885\tData 0.1046\tLoss 0.6568\tAcc 78.97\n",
      "Test: [20/20]\tTime 0.6023\tData 0.1620\tLoss 0.6931\tAcc 77.80\n",
      "\n",
      "Finished Training\n",
      "\n",
      "Total Average Training Time : 44.20 ± 3.76 sec\n",
      "Total Average Validation Time : 10.27 ± 1.25 sec\n",
      "\n",
      "Total Best Validation Accuracy : 80.27 %\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "train_time = []\n",
    "val_time = []\n",
    "\n",
    "for idx in range(epoch):  # loop over the dataset multiple times\n",
    "\n",
    "    # train for one epoch\n",
    "    end = time.time()\n",
    "    train(train_loader, model, criterion, optimizer, idx, device)\n",
    "    train_time.append(time.time() - end)\n",
    "\n",
    "    # evaluate on validation set\n",
    "    end = time.time()\n",
    "    acc = validate(val_loader, model, criterion, device)\n",
    "    val_time.append(time.time() - end)\n",
    "\n",
    "    # remember best acc and save checkpoint\n",
    "    is_best = acc > best_acc\n",
    "    best_acc = max(acc, best_acc)\n",
    "\n",
    "    save_checkpoint({\n",
    "            'epoch': idx + 1,\n",
    "            'arch': \"ResNet-18\",\n",
    "            'state_dict': model.state_dict(),\n",
    "            'best_acc1': best_acc,\n",
    "            'optimizer' : optimizer.state_dict(),\n",
    "        }, is_best)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "train_time = np.array(train_time)\n",
    "val_time = np.array(val_time)\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Average Training Time : %.2f ± %.2f\" % (train_time.mean(), train_time.std()), \"sec\")\n",
    "print(\"Total Average Validation Time : %.2f ± %.2f\" % (val_time.mean(), val_time.std()), \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % best_acc.real, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine-tuning LDA instead of Fully Connected Layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.NCM_Classifier import train, validate, save_checkpoint\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "num_class = 10\n",
    "\n",
    "model = resnet18(pretrained=True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finished Training\n",
      "\n",
      "Total Training Time : 65.79 sec\n",
      "Total Validation Time : 10.95 sec\n",
      "\n",
      "Total Best Validation Accuracy : 86.19 %\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "\n",
    "# train for one epoch\n",
    "end = time.time()\n",
    "x_train, y_train = train(train_loader, model, device)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "train_time = time.time() - end\n",
    "\n",
    "# evaluate on validation set\n",
    "end = time.time()\n",
    "x_test, y_test = validate(val_loader, model, device)\n",
    "\n",
    "test_score = lda.score(x_test, y_test)\n",
    "val_time = time.time() - end\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Training Time : %.2f\" % train_time, \"sec\")\n",
    "print(\"Total Validation Time : %.2f\" % val_time, \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % (test_score*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA Shape :  (50000, 9)\n",
      "\n",
      "Finished Training\n",
      "\n",
      "Total Training Time : 94.83 sec\n",
      "Total Validation Time : 19.33 sec\n",
      "\n",
      "Total Best Validation Accuracy : 68.69 %\n"
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "\n",
    "# train for one epoch\n",
    "end = time.time()\n",
    "x_train, y_train = train(train_loader, model, device)\n",
    "\n",
    "pca = PCA(n_components=9, random_state=0)\n",
    "x_train = pca.fit_transform(x_train)\n",
    "print(\"PCA Shape : \", x_train.shape)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis()\n",
    "lda.fit(x_train, y_train)\n",
    "train_time = time.time() - end\n",
    "\n",
    "# evaluate on validation set\n",
    "end = time.time()\n",
    "x_test, y_test = validate(val_loader, model, device)\n",
    "\n",
    "x_test = pca.transform(x_test)\n",
    "\n",
    "test_score = lda.score(x_test, y_test)\n",
    "val_time = time.time() - end\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Training Time : %.2f\" % train_time, \"sec\")\n",
    "print(\"Total Validation Time : %.2f\" % val_time, \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % (test_score*100), \"%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 9)\n",
      "(10000, 9)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "X has 9 features, but LinearDiscriminantAnalysis is expecting 512 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-aba21fce3579>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mx_test\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m \u001b[0mtest_score\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     19\u001b[0m \u001b[0mval_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mend\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    649\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    650\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 651\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    652\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    653\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_more_tags\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    423\u001b[0m             \u001b[0mVector\u001b[0m \u001b[0mcontaining\u001b[0m \u001b[0mthe\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0meach\u001b[0m \u001b[0msample\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    424\u001b[0m         \"\"\"\n\u001b[1;32m--> 425\u001b[1;33m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    426\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    427\u001b[0m             \u001b[0mindices\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mscores\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\discriminant_analysis.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    704\u001b[0m         \"\"\"\n\u001b[0;32m    705\u001b[0m         \u001b[1;31m# Only override for the doc\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 706\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    708\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\linear_model\\_base.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    405\u001b[0m         \u001b[0mcheck_is_fitted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    406\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"csr\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m         \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msafe_sparse_dot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcoef_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdense_output\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mintercept_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mscores\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    583\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    584\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mno_val_X\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcheck_params\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"ensure_2d\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 585\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_n_features\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreset\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreset\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    586\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\Users\\LAB\\Anaconda3\\envs\\lab\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_check_n_features\u001b[1;34m(self, X, reset)\u001b[0m\n\u001b[0;32m    398\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    399\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_in_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 400\u001b[1;33m             raise ValueError(\n\u001b[0m\u001b[0;32m    401\u001b[0m                 \u001b[1;34mf\"X has {n_features} features, but {self.__class__.__name__} \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    402\u001b[0m                 \u001b[1;34mf\"is expecting {self.n_features_in_} features as input.\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: X has 9 features, but LinearDiscriminantAnalysis is expecting 512 features as input."
     ]
    }
   ],
   "source": [
    "best_acc = 0.\n",
    "\n",
    "# train for one epoch\n",
    "end = time.time()\n",
    "x_train, y_train = train(train_loader, model, device)\n",
    "\n",
    "lda = LinearDiscriminantAnalysis(n_components=9)\n",
    "x_train = lda.fit_transform(x_train, y_train)\n",
    "print(x_train.shape)\n",
    "train_time = time.time() - end\n",
    "\n",
    "# evaluate on validation set\n",
    "end = time.time()\n",
    "x_test, y_test = validate(val_loader, model, device)\n",
    "\n",
    "x_test = lda.transform(x_test)\n",
    "print(x_test.shape)\n",
    "test_score = lda.score(x_test, y_test)\n",
    "val_time = time.time() - end\n",
    "\n",
    "print('\\nFinished Training\\n')\n",
    "print(\"Total Training Time : %.2f\" % train_time, \"sec\")\n",
    "print(\"Total Validation Time : %.2f\" % val_time, \"sec\")\n",
    "print(\"\\nTotal Best Validation Accuracy : %.2f\" % (test_score*100), \"%\")"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7a4110d7404e15bb29e9af898bb3709c8ad5c91368ac9d283907772f906a4946"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 ('lab')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
